{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Book_Deep_Learning_NLP_Jason Brownlee_2020_Foundation.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "3vP2ad0yZsPa",
        "uZIYp85nJiYs",
        "zyfz0axvKv_W",
        "V9qSyWeiKEYf"
      ],
      "mount_file_id": "1qJrm-4pGIievAqN2pa1ltkMcPwDCaVSa",
      "authorship_tag": "ABX9TyPlXQlKYkOgkECV0bBAshgu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MohebZandi/Deep_Learning_NLP/blob/main/Book_Deep_Learning_NLP_Jason_Brownlee_2020_Foundation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Book_Deep_Learning_NLP_Jason Brownlee_2020**\n",
        "\n",
        "> Indented block\n",
        "\n"
      ],
      "metadata": {
        "id": "XpP-LrpbTU5R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part II\n",
        "### Foundations\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "kf082u6TTO4q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### Chapter 1\n",
        "#### Natural Language Processing\n",
        "\n",
        "What natural language is and how it is different from other types of data.\n",
        "\n",
        "What makes working with natural language so challenging.\n",
        "\n",
        "Where the field of NLP came from and how it is defined by modern practitioners.\n",
        "\n",
        "\n",
        "#### Chapter 2\n",
        "#### Deep Learning\n",
        "\n",
        "-  The motivation for exploring and adopting large neural network models.\n",
        "-  The perspective on deep learning as hierarchical feature learning.\n",
        "-  The promise of scalability of deep learning with the size of data.\n",
        "\n",
        "\n",
        "\n",
        "#### Chapter 3\n",
        "#### Promise of Deep Learning for Natural Language\n",
        "\n",
        "1- The Promise of Drop-in Replacement Models. That is, deep learning methods can\n",
        "be dropped into existing natural language systems as replacement models that can achieve\n",
        "commensurate or better performance.\n",
        "\n",
        "2- The Promise of New NLP Models. That is, deep learning methods o\u000ber the op-\n",
        "portunity of new modeling approaches to challenging natural language problems like\n",
        "sequence-to-sequence prediction.\n",
        "\n",
        "3- The Promise of Feature Learning. That is, that deep learning methods can learn\n",
        "the features from natural language required by the model, rather than requiring that the\n",
        "features be specified and extracted by an expert.\n",
        "\n",
        "4- The Promise of Continued Improvement. That is, that the performance of deep\n",
        "learning in natural language processing is based on real results and that the improvements\n",
        "appear to be continuing and perhaps speeding up.\n",
        "\n",
        "5- The Promise of End-to-End Models. That is, that large end-to-end deep learning\n",
        "models can be fit on natural language problems o\u000bering a more general and better-\n",
        "performing approach.\n",
        "\n",
        "#### Chapter 4\n",
        "#### How to Develop Deep Learning Models With Keras\n",
        "\n",
        "Keras Model Life-Cycle\n",
        "\n",
        "Below is an overview of the 5 steps in the neural network model life-cycle in Keras:\n",
        "1. Define Network.\n",
        "2. Compile Network.\n",
        "3. Fit Network.\n",
        "4. Evaluate Network.\n",
        "5. Make Predictions.\n",
        "\n"
      ],
      "metadata": {
        "id": "HfQvrc5F9Xmk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NAwNfwCsSo8t"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler(feature_range = (0, 1))\n",
        "\n",
        "from keras.layers import LSTM, Bidirectional, Dense, Activation\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from keras.models import Sequential\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from tensorflow.keras.optimizers import Adam,Nadam, SGD\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Define Network\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(2))\n",
        "\n",
        "# or\n",
        "\n",
        "layers = [Dense(2)]\n",
        "model = Sequential(layers)"
      ],
      "metadata": {
        "id": "qPn9FxTSStvL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For example, a small Multilayer Perceptron model\n",
        "# with 2 inputs in the visible layer, 5 neurons in the hidden layer and one neuron in the output\n",
        "# layer can be defined as:\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(5, input_dim=2))\n",
        "model.add(Dense(1))\n"
      ],
      "metadata": {
        "id": "SJiB_8cYS8lK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# activation functions that transform a summed signal from each neuron in a layer can be extracted and\n",
        "# added to the Sequential as a layer-like object called the Activation class.\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(5, input_dim=2))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))"
      ],
      "metadata": {
        "id": "WKPhM0LcUhce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The choice of Activation function is most important for the output layer as it will define the format that predictions will take. \n",
        "\n",
        "For example, below are some common predictive modeling\n",
        "problem types and the structure and standard activation function that you can use in the output\n",
        "\n",
        "layer:\n",
        "1- Regression: Linear activation function, or *linear*, and the number of neurons matching\n",
        "the number of outputs.\n",
        "\n",
        "2- Binary Classification (2 class): Logistic activation function, or *sigmoid*, and one\n",
        "neuron the output layer.\n",
        "\n",
        "3- Multiclass Classification (>2 class): Softmax activation function, or *softmax*, and\n",
        "one output neuron per class value, assuming a one hot encoded output pattern."
      ],
      "metadata": {
        "id": "9pPlOTRAViOZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Compile Network\n",
        "\n",
        "# Example of compiling a defined model.\n",
        "model.compile(optimizer='sgd', loss='mean_squared_error')"
      ],
      "metadata": {
        "id": "xLcvcEtMVLoA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Alternately, the optimizer can be created and configured before being provided as an argument\n",
        "# to the compilation step.\n",
        "\n",
        "algorithm = SGD(lr=0.1, momentum=0.3)\n",
        "model.compile(optimizer=algorithm, loss='mean_squared_error')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjQ463SMWVHx",
        "outputId": "40ced94e-bbd6-41a8-dcb5-764d670a1672"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below are some standard loss functions for di\u000berent predictive\n",
        "model types:\n",
        "\n",
        "- Regression: Mean Squared Error or *mean_squared_error*.\n",
        "\n",
        "- Binary Classification (2 class): Logarithmic Loss, also called cross-entropy or\n",
        "*binary_crossentropy*.\n",
        "\n",
        "- Multiclass Classification (>2 class): Multiclass Logarithmic Loss or *categorical_crossentropy*."
      ],
      "metadata": {
        "id": "Vd6mpik9X7mS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The most common optimization algorithm is *stochastic gradient descent(sgd)*, but Keras also\n",
        "supports a suite of other state-of-the-art optimization algorithms that work well with little or\n",
        "no configuration. Perhaps the most commonly used optimization algorithms because of their\n",
        "generally better performance are:\n",
        "\n",
        "- Stochastic Gradient Descent, or *sgd*, that requires the tuning of a learning rate and\n",
        "momentum.\n",
        "\n",
        "- Adam, or *adam*, that requires the tuning of learning rate.\n",
        "\n",
        "- RMSprop, or *rmsprop*, that requires the tuning of learning rate."
      ],
      "metadata": {
        "id": "4ti4TZdSYhRK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generally, the most useful additional metric to collect is accuracy for classification\n",
        "# problems. The metrics to collect are specified by name in an array. For example:\n",
        "\n",
        "model.compile(optimizer='sgd', loss='mean_squared_error', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "NfDQkRbCW-nu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3. Fit Network\n",
        "\n",
        "Once the network is compiled, it can be fit, which means adapt the weights on a training dataset.\n",
        "\n",
        "Fitting the network requires the training data to be specified, both a matrix of input patterns, X,\n",
        "and an array of matching output patterns, y."
      ],
      "metadata": {
        "id": "3vP2ad0yZsPa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example of fitting a compiled model.**\n",
        "\n",
        "history = model.fit(X, y, batch_size=10, epochs=100)\n",
        "\n",
        "#\n",
        "\n",
        "#\n",
        "\n",
        "Once fit, a history object is returned that provides a summary of the performance of the\n",
        "model during training. \n",
        "\n",
        "This includes both the loss and any additional metrics specified when\n",
        "compiling the model, recorded each epoch."
      ],
      "metadata": {
        "id": "XbAN0vdta9_Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can reduce the amount of information displayed to just the\n",
        "loss each epoch by setting the verbose argument to 2. \n",
        "\n",
        "You can turn off all output by setting\n",
        "verbose to 0. For example:\n",
        "\n",
        "#\n",
        "\n",
        "history = model.fit(X, y, batch_size=10, epochs=100, verbose=0)"
      ],
      "metadata": {
        "id": "4Lmrv82rbv6p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 4. Evaluate Network**\n",
        "\n",
        "The model evaluates the loss across all of the test patterns, as well as any other metrics\n",
        "specified when the model was compiled, like classification accuracy. \n",
        "\n",
        "A list of evaluation metrics\n",
        "is returned. \n",
        "\n",
        "For example, for a model compiled with the accuracy metric, we could evaluate it\n",
        "on a new dataset as follows:\n",
        "\n",
        "loss, accuracy = model.evaluate(X, y)\n",
        "\n",
        "#\n",
        "\n",
        "#\n",
        "\n",
        "Turn off verbose:\n",
        "\n",
        "loss, accuracy = model.evaluate(X, y, verbose=0)"
      ],
      "metadata": {
        "id": "-H_Bc_aucGUw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 5. Make Predictions**\n",
        "\n",
        "Once we are satisfied with the performance of our fit model, we can use it to make predictions\n",
        "on new data. \n",
        "\n",
        "This is as easy as calling the *predict()* function on the model with an array of\n",
        "new input patterns. \n",
        "\n",
        "For example:\n",
        "\n",
        "predictions = model.predict(X)\n",
        "\n",
        "\n",
        "The predictions will be returned in the format provided by the output layer of the network.\n",
        "\n",
        "- In the case of a regression problem, these predictions may be in the format of the problem\n",
        "directly, provided by a linear activation function. \n",
        "\n",
        "- For a binary classification problem, the\n",
        "predictions may be an array of probabilities for the first class that can be converted to a 1 or 0\n",
        "by rounding.\n",
        "\n",
        "- For a multiclass classification problem, the results may be in the form of an array of\n",
        "probabilities (assuming a one hot encoded output variable) that may need to be converted to a\n",
        "single class output prediction using the *argmax()* NumPy function. \n",
        "\n",
        "Alternately, for classification\n",
        "problems, we can use the *predict_classes()* function that will automatically convert uncrisp\n",
        "predictions to crisp integer class values.\n",
        "\n",
        "predictions = model.predict_classes(X)"
      ],
      "metadata": {
        "id": "GHr7cr4ycwSR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Standard Network Models"
      ],
      "metadata": {
        "id": "uZIYp85nJiYs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Multilayer Perceptron\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import Dense\n",
        "visible = Input(shape=(10,))\n",
        "hidden1 = Dense(10, activation='relu')(visible)\n",
        "hidden2 = Dense(20, activation='relu')(hidden1)\n",
        "hidden3 = Dense(10, activation='relu')(hidden2)\n",
        "output = Dense(1, activation='sigmoid')(hidden3)\n",
        "model = Model(inputs=visible, outputs=output)\n",
        "# summarize layers\n",
        "model.summary()\n",
        "# plot graph\n",
        "plot_model(model, to_file='multilayer_perceptron_graph.png')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 811
        },
        "id": "CmCYrdHSZOW1",
        "outputId": "585c3df6-6fbc-4016-a38b-a50fbdc95633"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 10)]              0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 10)                110       \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 20)                220       \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 10)                210       \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 551\n",
            "Trainable params: 551\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMgAAAHBCAIAAACjQmO1AAAABmJLR0QA/wD/AP+gvaeTAAAgAElEQVR4nO3de1hT9/0H8M9JQq6QcGkQaYAadKJc6nwspYgrrWOVuvlUCSMqIlg6retaZ7V04phzdZaho09bqEOtfbqtGMTV26bdipZufaAPbqhVbgLj1ggBTImQyCWc3x/n1zyMSwjkfJOAn9dfngvfm2/O+eZwcg5F0zQgxDaOsxuAZicMFiICg4WIwGAhIngjF8rKyn7/+987qyloRtu5c+cTTzxhWfyfI1Zra2txcbHDm+R85eXl5eXlzm7FDFZcXNza2jpyDW/sTqdOnXJUe1xFYmIiPJAdZwtFUaPW4BwLEYHBQkRgsBARGCxEBAYLEYHBQkRgsBARGCxEBAYLEYHBQkRgsBARGCxEBAYLEYHBQkRMJ1h/+9vfZDLZ+fPnWW+N/YaHh3Nzc6Ojo1kvuby8fNGiRRwOh6KoOXPmvPHGG6xXMZHTp08rlUqKoiiK8vPzS05OdljV0zbO/ViTctlvjN2+fTstLe2LL7549NFHWS88Kiqqurp61apVn3zySW1traenJ+tVTCQhISEhIWH+/PldXV3t7e0Oq9ce0zlirV69uqen50c/+hHrrRnFZDLZfuy5fv3666+//uKLLy5ZsoRoqxxjSn13QS49xzp+/LhOp7Nx50cfffT06dMbN24UCAREW+UYU+q7C5pysP71r38FBgZSFPXuu+8CQH5+vkQiEYvFZ8+ejY+Pl0qlCoWisLCQ2fntt98WCoW+vr7btm2bO3euUCiMjo7+8ssvma0vv/wyn8/38/NjFn/6059KJBKKorq6ugBgx44dr776akNDA0VR8+fPZ6e7rHK1vv/zn/9cvHixTCYTCoXh4eGffPIJAKSnpzOTs+Dg4MrKSgBIS0sTi8UymezcuXMAYDabs7KyAgMDRSJRRESERqMBgN/97ndisdjDw0On07366qsPP/xwbW3t1EaHHoEplJ4Mc9v8O++8wyxmZmYCQElJSU9Pj06nW7FihUQiGRgYYLZu3bpVIpFUVVXdv3//1q1bjz32mIeHR0tLC7N148aNc+bMsZSck5MDAJ2dncxiQkJCcHDwpO0Z5fHHH3/00Uen9CMqlUqlUtmy5zPPPAMAer2eWXRk34ODg2UymZW2nTp1at++fXfv3u3u7o6KivLx8bEUxeVyv/76a8ueGzZsOHfuHPPvXbt2CQSC4uJivV6/Z88eDodTUVFh6dorr7zyzjvvrFu3rrq62krVAKDRaEauYe1UGB0dLZVK5XK5Wq3u6+traWmxbOLxeIsWLRIIBIsXL87Pz793796JEyfYqtcVuEjfVSrVr371Ky8vL29v7zVr1nR3d3d2dgLAiy++aDabLfUaDIaKiopnn30WAO7fv5+fn7927dqEhARPT8+9e/e6ubmNbOGbb7750ksvnT59OiQkZEqNYX+OxefzAWBwcHDcrcuWLROLxTU1NazX6wpcp+9ubm4AYDabAeDpp5/+zne+8/777zOHlpMnT6rVai6XCwC1tbVGozEsLIz5KZFI5Ofnx0oLnTB5FwgEzG/SA4ho3//617/GxsbK5XKBQPDaa69Z1lMUtW3btsbGxpKSEgD48MMPn3/+eWZTX18fAOzdu5f6VnNzs9FotL8xjg7W4ODgN998o1AoHFyvKyDR988//zw3NxcAWlpa1q5d6+fn9+WXX/b09GRnZ4/cLTU1VSgUHjt2rLa2ViqVBgUFMevlcjkA5ObmjpwelZWV2d+w6Vwgtcdnn31G03RUVNT/V8/jTXTimH1I9P3f//63RCIBgK+++mpwcHD79u1KpRLGfIPUy8srKSnp5MmTHh4eL7zwgmV9QECAUCi8du2anc0YyxFHrOHhYb1ePzQ0dOPGjR07dgQGBqampjKb5s+ff/fu3TNnzgwODnZ2djY3N4/8QW9vb61W29TUdO/evRmaP3J9Hxwc7Ojo+Oyzz5hgBQYGAsCnn356//7927dvW65rWLz44ov9/f0XLlwYeWVbKBSmpaUVFhbm5+cbDAaz2dzW1nbnzh0Wej7yGGjL5YZ33nmHufoiFovXrFmTl5cnFosBYMGCBQ0NDQUFBVKpFACCgoLq6upomt66daubm9vDDz/M4/GkUulzzz3X0NBgKa27u/upp54SCoXz5s372c9+tnv3bmbEmc/k//nPf4KCgkQiUUxMTHt7u/WGlZWVLV++fO7cuUy//Pz8oqOjS0tLrf8Uw5bLDeXl5aGhoRwOhyn8wIEDDuv7e++9FxwcPNH/4F/+8hemwIyMDG9vb09Pz8TEROYqY3BwsOXqBk3T3/3ud3/xi1+M6ld/f39GRkZgYCCPx5PL5QkJCbdu3crOzhaJRAAQEBDwxz/+cdIBhDGXG6ZzHWtKtm7d6u3tzW6ZrLP9OtaUuFrfn3322cbGRhIljw2WI06FzIfeB5PT+245jd64cYM5OjqmXpf+W6FFTU0NNTG1Wu3sBrqujIyM27dv19XVpaWl/eY3v3FYvWSDtWfPnhMnTvT09MybN8+eJ2+FhIRYOQ6fPHmSxTazha2+20ksFoeEhHz/+9/ft2/f4sWLHVYvRY+4uaqoqCgpKYl21dutyMHnY9mJoiiNRvPjH//YsmZmnArRjIPBQkRgsBARGCxEBAYLEYHBQkRgsBARGCxEBAYLEYHBQkRgsBARGCxEBAYLETHOlymYP/U/UJh3yj2AHSfnf4IVEBCgUqmc1RQnsnxzxoqrV68CwLJly8g3Z+ZRqVQBAQEj11AP4N1X08PcbFRUVOTshswMOMdCRGCwEBEYLEQEBgsRgcFCRGCwEBEYLEQEBgsRgcFCRGCwEBEYLEQEBgsRgcFCRGCwEBEYLEQEBgsRgcFCRGCwEBEYLEQEBgsRgcFCRGCwEBEYLEQEBgsRgcFCRGCwEBEYLEQEBgsRgcFCRGCwEBEYLEQEBgsRgcFCROAT/Sb0wQcfvPXWW5a3hXd2dgKAXC5nFrlc7o4dO1JTU53VPBeHwZpQbW1tSEiIlR2qq6ut7/Agw1PhhBYuXBgeHk5R1NhNFEWFh4djqqzAYFmTkpLC5XLHrufxeJs3b3Z8e2YQPBVao9VqFQrF2CGiKKqlpUWhUDilVTMCHrGs8ff3j46O5nD+Z5Q4HE50dDSmyjoM1iQ2bdo0appFUVRKSoqz2jNT4KlwEnfv3p0zZ87Q0JBlDZfL7ejo8PHxcWKrXB8esSbh7e0dFxfH4/3/u2G4XG5cXBymalIYrMklJycPDw8z/6ZpetOmTc5tz4yAp8LJ9fX1PfTQQ/fv3wcAgUDQ1dXl7u7u7Ea5OjxiTU4ikaxZs8bNzY3H4z333HOYKltgsGyycePGoaEhs9m8YcMGZ7dlZhjnRZhT9SC8ac1sNguFQpqme3t7H4T+Mu/QswcLc6xx/5qGZjT7U8HOqVCj0dCz3eXLl69cuTJ2vUqlUqlUDm8OKRqNhpVIsHAqfEA8+eSTzm7CTILBstWovxgi63CwEBEYLEQEBgsRgcFCRGCwEBEYLEQEBgsRgcFCRGCwEBEYLEQEBgsRgcFCRDghWOnp6R4eHhRFXbt2zfG1T2RwcPC3v/3t/Pnz+Xy+p6dnWFhYU1MTW4WfPn1aqVRSI/D5fF9f39jY2JycHL1ez1ZFrsMJwTp27NjRo0cdX691SUlJH3744Z///Gej0VhdXR0cHNzb28tW4QkJCY2NjcHBwTKZjKbp4eFhnU5XVFQ0b968jIyM0NDQq1evslWXi8DbZgAATp48eebMmevXr4eHhwPA3Llzz549S646iqI8PT1jY2NjY2NXr16dlJS0evXquro6mUxGrlIHc84cy9XuZn7vvfeWLl3KpMrBVCpVamqqTqc7cuSI42snx0HBomk6Jydn4cKFAoFAJpPt3r175Faz2ZyVlRUYGCgSiSIiIpi7Y/Pz8yUSiVgsPnv2bHx8vFQqVSgUhYWFlp8qLS2NjIwUi8VSqTQ8PNxgMExUlHUDAwPl5eVLlixhu9O2Yh4LePHiRWbRuaPBGvvvkgYb7nnPzMykKOrw4cN6vd5oNObl5QFAZWUls3XXrl0CgaC4uFiv1+/Zs4fD4VRUVDA/BQAlJSU9PT06nW7FihUSiWRgYICm6d7eXqlUmp2dbTKZ2tvb161b19nZaaUoK/773/8CwJIlS2JjY/38/AQCQUhIyLvvvjs8PGxL922/590yxxqFCUFAQIArjAYTPlu6Y50jgmU0GsVicVxcnGUN86vGBMtkMonFYrVabdlZIBBs376d/nYoTSYTs4mJY319PU3TN2/eBIALFy6MrMhKUVZ89dVXABAXF/fFF190d3d/8803r7/+OgD86U9/sqX79geLpmlm1mW9C44ZDbaC5YhTYX19vdFoXLly5bhba2trjUZjWFgYsygSifz8/GpqasbuyefzAWBwcBAAlEqlr69vcnLyvn37LNcFbC9qJIFAAAChoaHR0dHe3t4ymezXv/61TCYrKCiYRmenoa+vj6ZpqVQKLjAabHFEsNra2mDE84ZH6evrA4C9e/darvE0NzcbjUbrZYpEosuXL8fExBw4cECpVKrVapPJNL2i5s6dCwBdXV2WNXw+PygoqKGhYSq9nL66ujoAYJ5o6vTRYIsjgiUUCgGgv79/3K1M4HJzc0ceSMvKyiYtNjQ09Pz581qtNiMjQ6PRHDp0aHpFubu7L1iwoKqqauTKoaEhh334v3TpEgDEx8eDC4wGWxwRrLCwMA6HU1paOu7WgIAAoVA41avwWq2WiYJcLj948ODSpUurqqqmVxQAJCUlVVZWNjY2MotGo7G5udkxVx/a29tzc3MVCsWWLVvANUaDFY4IllwuT0hIKC4uPn78uMFguHHjxsjpi1AoTEtLKywszM/PNxgMZrO5ra3tzp071svUarXbtm2rqakZGBiorKxsbm6OioqaXlEAsHPnzqCgoNTU1JaWlu7u7oyMDJPJxEzh2UXTdG9vL/N5s7OzU6PRLF++nMvlnjlzhpljucJosMP++T/YcLnh3r176enpPj4+7u7uMTExWVlZAKBQKK5fv07TdH9/f0ZGRmBgII/HY1J469atvLw8sVgMAAsWLGhoaCgoKGCGPigoqK6urqmpKTo62svLi8vl+vv7Z2ZmDg0NTVSULb1obW1dv369l5eXQCCIjIy8ePGijd235VPhuXPnIiIixGIxn89nvvjKfAyMjIzcv39/d3f3yJ2dOxpsfSpk56EgGo3G/ueTzFCJiYkAcOrUKWc3hB1FRUVJSUn2pwJvm0FEzP5g1dTUUBNTq9XObuDsNPvvbggJCbH/wI6mavYfsZBTYLAQERgsRAQGCxGBwUJEYLAQERgsRAQGCxGBwUJEYLAQERgsRAQGCxGBwUJEYLAQEezcNuOw7364IObLbbPmJYZs/Vfi+wrROFhIBd4EZyPmpv5Zc2QiDedYiAgMFiICg4WIwGAhIjBYiAgMFiICg4WIwGAhIjBYiAgMFiICg4WIwGAhIjBYiAgMFiICg4WIwGAhIjBYiAgMFiICg4WIwGAhIjBYiAgMFiICg4WIwGAhIjBYiAgMFiICg4WIwGAhIjBYiAgMFiICg4WIwGAhIjBYiIjZ/+reaSstLS0vL7cs1tTUAEB2drZlTVRU1JNPPumEls0E+KjICf3jH//4wQ9+4ObmxuGMPq4PDw8PDg7+/e9/j4uLc0rbXB8Ga0Jms3nOnDnd3d3jbvXy8tLpdDweHvLHh3OsCXG53I0bN/L5/LGb+Hz+pk2bMFVWYLCsWb9+/cDAwNj1AwMD69evd3x7ZhA8FU4iKCiopaVl1EqFQtHS0oIPuLcCj1iTSE5OdnNzG7mGz+dv3rwZU2UdHrEmUV1dvXjx4lErv/rqq7CwMKe0Z6bAYE1u8eLF1dXVlsWQkJCRi2hceCqcXEpKiuVs6ObmtnnzZue2Z0bAI9bkWlpaHnnkEWagKIpqbGx85JFHnN0oV4dHrMkFBgYuW7aMw+FQFPXYY49hqmyBwbJJSkoKh8PhcrmbNm1ydltmBjwV2qSzs3Pu3LkA8PXXX8+ZM8fZzZkB8EWYaBz2p4Kdv3bt2LHjiSeeYKUol1VaWkpR1Pe+971R63NzcwHg5z//uTMaxb6ysrK33nrL/nLYCdYTTzzBvIB0Flu1ahUASKXSUetPnToF375/dXZwoWA9CMZGClmBnwoRERgsRAQGCxGBwUJEYLAQERgsRAQGCxGBwUJEYLAQERgsRAQGCxGBwUJEYLAQEU4IVnp6uoeHB0VR165dc3zt44qNjaXGcHd3Z6v806dPK5XKkYXz+XxfX9/Y2NicnBy9Xs9WRa7DCcE6duzY0aNHHV/vVMXExLBVVEJCQmNjY3BwsEwmo2l6eHhYp9MVFRXNmzcvIyMjNDT06tWrbNXlIvBUCAAgFAoNBgM9wtatW1977TVC1VEU5enpGRsbe+LEiaKioo6OjtWrV/f09BCqzimcEyxXu03+0qVLHh4elsXW1tabN28+/fTTDqhapVKlpqbqdLojR444oDqHcVCwaJrOyclZuHChQCCQyWS7d+8eudVsNmdlZQUGBopEooiICI1GAwD5+fkSiUQsFp89ezY+Pl4qlSoUisLCQstPlZaWRkZGisViqVQaHh5uMBgmKmqq3nzzzVdeecW+Hk9BamoqAFy8eJFZdLXRmCbabgCg0Wis75OZmUlR1OHDh/V6vdFozMvLA4DKykpm665duwQCQXFxsV6v37NnD4fDqaioYH4KAEpKSnp6enQ63YoVKyQSycDAAE3Tvb29Uqk0OzvbZDK1t7evW7eus7PTSlG2a2trW7x4sdlstnF/lUqlUqls2dMyxxqFCUFAQACz6NzRYMJnY9+tcESwjEajWCyOi4uzrGF+1ZhgmUwmsVisVqstOwsEgu3bt9PfDqXJZGI2MXGsr6+nafrmzZsAcOHChZEVWSnKdi+99NJ7771n+/72B4umaWbWRbvAaLAVLEecCuvr641G48qVK8fdWltbazQaLU8FEolEfn5+zCOKR2Ge2jg4OAgASqXS19c3OTl53759TU1NUy1qIlqt9ty5c8y5yWH6+vpomma+rOFSo2EPRwSrra0NAORy+bhb+/r6AGDv3r2WazzNzc1Go9F6mSKR6PLlyzExMQcOHFAqlWq12mQyTa+okbKzs1944QWhUGj7j9ivrq4OAEJCQsDFRsMejggW8//U398/7lYmcLm5uSMPpGVlZZMWGxoaev78ea1Wm5GRodFoDh06NO2iGO3t7R999NH27dtt7RhLLl26BADx8fHgSqNhJ0cEKywsjMPhlJaWjrs1ICBAKBRO9Sq8VqutqqoCALlcfvDgwaVLl1ZVVU2vKIvs7Ozk5GRvb+/p/fj0tLe35+bmKhSKLVu2gCuNhp0cESy5XJ6QkFBcXHz8+HGDwXDjxo2CggLLVqFQmJaWVlhYmJ+fbzAYzGZzW1vbnTt3rJep1Wq3bdtWU1MzMDBQWVnZ3NwcFRU1vaIYHR0d77//PulvytM03dvbOzw8TNN0Z2enRqNZvnw5l8s9c+YMM8dykdFggf3zf7DhcsO9e/fS09N9fHzc3d1jYmKysrIAQKFQXL9+nabp/v7+jIyMwMBAHo/HpPDWrVt5eXlisRgAFixY0NDQUFBQwAx9UFBQXV1dU1NTdHS0l5cXl8v19/fPzMwcGhqaqChberFz587k5ORpdN+WT4Xnzp2LiIgQi8V8Pp95zwXzMTAyMnL//v3d3d0jd3buaLD1qZCdp81oNJrZ9PCCKUlMTIRvn+AwCxQVFSUlJdmfCvxbISJi9gerpqZm7C0xFmq12tkNnJ1m/9NmQkJC7D+wo6ma/Ucs5BQYLEQEBgsRgcFCRGCwEBEYLEQEBgsRgcFCRGCwEBEYLEQEBgsRgcFCRGCwEBEYLEQEvq8QjcP+VLBwP5ZDnwjgPLPsvYSk4at7bcXc1F9UVOTshswMOMdCRGCwEBEYLEQEBgsRgcFCRGCwEBEYLEQEBgsRgcFCRGCwEBEYLEQEBgsRgcFCRGCwEBEYLEQEBgsRgcFCRGCwEBEYLEQEBgsRgcFCRGCwEBEYLEQEBgsRgcFCRGCwEBEYLEQEBgsRgcFCRGCwEBEYLEQEBgsRMfvfsDptXV1dBoPBstjX1wcAjY2NljVSqfShhx5yQstmhKm/+P5BcezYMetDd+zYMWe30XXhoyInpNfr58yZMzg4OO5WNze3jo4OLy8vB7dqpsA51oS8vLxWrVrF440zW+DxePHx8ZgqKzBY1iQnJ5vN5rHrzWZzcnKy49szg+Cp0Jr79+/7+PgYjcZR60UiUVdXl1gsdkqrZgQ8YlkjFArXrl3r5uY2cqWbm1tCQgKmyjoM1iQ2bNgwav4+ODi4YcMGZ7VnpsBT4SSGhoZ8fX31er1ljaenp06nG3UYQ6PgEWsSPB5PrVbz+Xxm0c3NbcOGDZiqSWGwJrd+/fqBgQHm34ODg+vXr3due2YEPBVOjqZphUKh1WoBwM/PT6vV4gvPJoVHrMlRFJWcnMzn893c3FJSUjBVtsBg2YQ5G+LnQduxcHdDYmKi/YW4Pnd3dwB44403nN0QRzh16pSdJbDzhtWoqCiFQmFnOS6uuroaABYtWjRqfXl5OQBERUU5oU0EtLW1lZeXs5AKVoKl0WiY90TOYg0NDQAQHBw8aj1zwLb/V9xFFBUVJSUl2Z8KvNHPVmMjhazAyTsiAoOFiMBgISIwWIgIDBYiAoOFiMBgISIwWIgIDBYiAoOFiMBgISIwWIgIDBYiwgnBSk9P9/DwoCjq2rVrjq99Ih999NFjjz3m4eERFBSUlpbW3t7OYuGnT59WKpXUCHw+39fXNzY2NicnZ+R3y2YNJwTr2LFjR48edXy9Vmg0mo0bNyYmJra1tZ09e/bzzz+Pj48fGhpiq/yEhITGxsbg4GCZTEbT9PDwsE6nKyoqmjdvXkZGRmho6NWrV9mqy0XgqRAA4A9/+IO/v//u3btlMtmSJUt27tx57dq1L7/8klB1FEV5enrGxsaeOHGiqKioo6Nj9erVPT09hKpzCucEy9W+6NLa2jp37lxLqwICAgCgubnZAVWrVKrU1FSdTnfkyBEHVOcwDgoWTdM5OTkLFy4UCAQymWz37t0jt5rN5qysrMDAQJFIFBERodFoACA/P18ikYjF4rNnz8bHx0ulUoVCUVhYaPmp0tLSyMhIsVgslUrDw8OZxzqOW9SklEqlTqezLDITLKVSyUrfJ5WamgoAFy9eZBadPhrssP+hgACg0Wis75OZmUlR1OHDh/V6vdFozMvLA4DKykpm665duwQCQXFxsV6v37NnD4fDqaioYH4KAEpKSnp6enQ63YoVKyQSycDAAE3Tvb29Uqk0OzvbZDK1t7evW7eus7PTSlHWffbZZ25ubm+//bbBYLh58+aiRYueeeYZG7uvUqlUKpUte1rmWKMwIQgICHCF0WDCZ2PfrXBEsIxGo1gsjouLs6xhftWYYJlMJrFYrFarLTsLBILt27fT3w6lyWRiNjFxrK+vp2n65s2bAHDhwoWRFVkpalJ79+61/LIpFIrW1lYbu29/sGiaZmZdtAuMBlvBcsSpsL6+3mg0rly5ctyttbW1RqMxLCyMWRSJRH5+fjU1NWP3ZJ7MwTxUSKlU+vr6Jicn79u3r6mpaapFjZKZmVlQUFBSUtLb29vY2BgdHf3EE0+0trZOuavT0tfXR9O0VCoF1xgNVjgiWG1tbQAgl8vH3co85nrv3r2WazzNzc1jH6I3ikgkunz5ckxMzIEDB5RKpVqtNplM0yvqzp072dnZP/nJT55++mmJRDJv3ryjR49qtdqcnJzp9Hbq6urqACAkJARcYDTY4ohgCYVCAOjv7x93KxO43NzckQfSsrKySYsNDQ09f/68VqvNyMjQaDSHDh2aXlG3b982m83+/v6WNVKp1Nvb+9atW7b30R6XLl0CgPj4eHCB0WCLI4IVFhbG4XBKS0vH3RoQECAUCqd6FV6r1VZVVQGAXC4/ePDg0qVLq6qqplcU8x3uO3fuWNbcu3fv7t27zEUH0trb23NzcxUKxZYtW8AFRoMtjgiWXC5PSEgoLi4+fvy4wWC4ceNGQUGBZatQKExLSyssLMzPzzcYDGazua2tbeR/87i0Wu22bdtqamoGBgYqKyubm5ujoqKmV9S8efOeeuqpo0ePfv755yaTqbW1devWrQDw/PPP29/3UWia7u3tHR4epmm6s7NTo9EsX76cy+WeOXOGmWM5fTRYY//8H2y43HDv3r309HQfHx93d/eYmJisrCwAUCgU169fp2m6v78/IyMjMDCQx+MxKbx161ZeXh7zANkFCxY0NDQUFBQwQx8UFFRXV9fU1BQdHe3l5cXlcv39/TMzM4eGhiYqatIudHV17dixY/78+QKBwN3dffny5R9//LGN3bflU+G5c+ciIiLEYjGfz+dwOPDtxffIyMj9+/d3d3eP3Nm5o8HWp0J8doO98NkN48K/FSIiZn+wampqqImp1WpnN3B2mv1PmwkJCbH/wI6mavYfsZBTYLAQERgsRAQGCxGBwUJEYLAQERgsRAQGCxGBwUJEYLAQERgsRAQGCxGBwUJEYLAQEfhaOXvha+XGxUKwHpAXYTJPGlq2bJmzG+IILvEizAcEc1N/UVGRsxsyM+AcCxGBwUJEYLAQERgsRAQGCxGBwUJEYLAQERgsRAQGCxGBwUJEYLAQERgsRAQGCxGBwUJEYLAQERgsRAQGCxGBwUJEYLAQERgsRAQGCxGBwUJEYLAQERgsRAQGCxGBwUJEYLAQERgsRAQGCxGBwUJEYLAQERgsRAQGCxGBT/Sb0AcffPDWW2+ZzWZmsbOzEwDkcjmzyOVyd+zYkZqa6qzmuTgM1oRqa2tDQkKs7FBdXW19hwcZngontHDhwvDwcIqixm6iKCo8PBxTZQUGy5qUlBQulzt2PY/H27x5s+PbM3cxzkEAAAbgSURBVIPgqdAarVarUCjGDhFFUS0tLQ/so+1tgUcsa/z9/aOjozmc/xklDocTHR2NqbIOgzWJTZs2jZpmURSVkpLirPbMFHgqnMTdu3fnzJkzNDRkWcPlcjs6Onx8fJzYKteHR6xJeHt7x8XF8Xg8ZpHL5cbFxWGqJoXBmlxycvLw8DDzb5qmN23a5Nz2zAh4KpxcX1/fQw89dP/+fQAQCARdXV3u7u7ObpSrwyPW5CQSyZo1a9zc3Hg83nPPPYepsgUGyyYbN24cGhoym80bNmxwdltmBp79RTwIb1ozm81CoZCm6d7e3gehv8w79OzBzhtW7SwBuRr7U8HOqVCj0dCz3eXLl69cuTJ2vUqlUqlUDm8OKRqNhpVIsHAqfEA8+eSTzm7CTILBstWovxgi63CwEBEYLEQEBgsRgcFCRGCwEBEYLEQEBgsRgcFCRGCwEBEYLEQEBgsRgcFCRDghWOnp6R4eHhRFXbt2zfG1j2twcDArK0upVPL5/IcffnjXrl0mk4nF8k+fPq1UKqkR+Hy+r69vbGxsTk6OXq9nsS5XYf8dPDD1+7EKCwsBoLKy0v7aWbF9+3ahUFhYWGgwGK5cuSKVSjds2GDjz9p+P1ZwcLBMJqNpenh4WK/XX7lyJTU1laKouXPnVlRUTL/1rGLux7K/HDwVQmNj45EjR1JSUtRqtYeHR2xs7Msvv/zRRx9VV1cTqpGiKE9Pz9jY2BMnThQVFXV0dKxevbqnp4dQdU7hnGC51N3MFRUVw8PDjz/+uGXNqlWrAOCTTz5xQO0qlSo1NVWn0x05csQB1TmMg4JF03ROTs7ChQsFAoFMJtu9e/fIrWazOSsrKzAwUCQSRUREMEfj/Px8iUQiFovPnj0bHx8vlUoVCgVzDmWUlpZGRkaKxWKpVBoeHm4wGCYqyjrmDj6RSGRZs2DBAgAgd8QahXks4MWLF5lF544Ga+w/m4INc6zMzEyKog4fPqzX641GY15eHoyYY+3atUsgEBQXF+v1+j179nA4HGbOkZmZCQAlJSU9PT06nW7FihUSiWRgYICm6d7eXqlUmp2dbTKZ2tvb161b19nZaaUoK27cuAEAv/zlLy1rmCc1rF271pbuT2OONQoTgoCAAFcYDbbmWI4IltFoFIvFcXFxljUjJ+8mk0ksFqvVasvOAoFg+/bt9LdDaTKZmE1MHOvr62mavnnzJgBcuHBhZEVWirJu1apV3t7eJSUlJpPpzp07RUVFFEX98Ic/tKX79geLpmlm1mW9C44ZjZk0ea+vrzcajStXrhx3a21trdFoDAsLYxZFIpGfn19NTc3YPfl8PgAMDg4CgFKp9PX1TU5O3rdvX1NT01SLGuXkyZOJiYkpKSne3t7Lly//+OOPaZp22JM/+vr6aJqWSqXgGqPBCkcEq62tDUY8b3iUvr4+ANi7d6/lGk9zc7PRaLRepkgkunz5ckxMzIEDB5RKpVqtNplM0ysKAGQy2ZEjR9ra2oxGY0NDw+HDhwHA399/qj2dnrq6OgBgnmjqCqPBCkcESygUAkB/f/+4W5nA5ebmjjyQlpWVTVpsaGjo+fPntVptRkaGRqM5dOjQtIsapaKiAgCeeuqpqf7g9Fy6dAkA4uPjwSVHY3ocEaywsDAOh1NaWjru1oCAAKFQONWr8FqttqqqCgDkcvnBgweXLl1aVVU1vaLGOnr06Lx58xzzRcL29vbc3FyFQrFlyxZwydGYHkcESy6XJyQkFBcXHz9+3GAw3Lhxo6CgwLJVKBSmpaUVFhbm5+cbDAaz2dzW1nbnzh3rZWq12m3bttXU1AwMDFRWVjY3N0dFRU2vKACIjIxsbm4eGhpqamratWvXp59+evz4cWYSwy6apnt7e4eHh2ma7uzs1Gg0y5cv53K5Z86cYeZYrjAa7LB//g82XG64d+9eenq6j4+Pu7t7TExMVlYWACgUiuvXr9M03d/fn5GRERgYyOPxmBTeunUrLy9PLBYDwIIFCxoaGgoKCpihDwoKqqura2pqio6O9vLy4nK5/v7+mZmZQ0NDExU1aRfi4uI8PT15PJ6Xl9fq1aun9AcWWz4Vnjt3LiIiQiwW8/l85rIZ8zEwMjJy//793d3dI3d27miw9amQnYeCaDQa+59PMkMlJiYCwKlTp5zdEHYUFRUlJSXZnwr8WyEiYvYHq6amhpqYWq12dgNnp9n/UJCQkBD7D+xoqmb/EQs5BQYLEYHBQkRgsBARGCxEBAYLEYHBQkRgsBARGCxEBAYLEYHBQkRgsBARGCxEBAYLEcHObTMO++6HC2K+3DZrXmLI1n8lvq8QjYOFVOBNcIgEnGMhIjBYiAgMFiICg4WI+D9l5ABXAyC6PwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convolutional Neural Network (CNN)\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import Dense\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.pooling import MaxPooling2D\n",
        "visible = Input(shape=(64,64,1))\n",
        "conv1 = Conv2D(32, (4,4), activation='relu')(visible)\n",
        "pool1 = MaxPooling2D()(conv1)\n",
        "conv2 = Conv2D(16, (4,4), activation='relu')(pool1)\n",
        "pool2 = MaxPooling2D()(conv2)\n",
        "hidden1 = Dense(10, activation='relu')(pool2)\n",
        "output = Dense(1, activation='sigmoid')(hidden1)\n",
        "model = Model(inputs=visible, outputs=output)\n",
        "# summarize layers\n",
        "model.summary()\n",
        "# plot graph\n",
        "plot_model(model, to_file='convolutional_neural_network.png')"
      ],
      "metadata": {
        "id": "cK1RW9X5a2jK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "315ec118-4058-4793-f4d9-3930971211a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 64, 64, 1)]       0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 61, 61, 32)        544       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 30, 30, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 27, 27, 16)        8208      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 13, 13, 16)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dense (Dense)               (None, 13, 13, 10)        170       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 13, 13, 1)         11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,933\n",
            "Trainable params: 8,933\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Recurrent Neural Network (RNN)\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import Dense\n",
        "from keras.layers.recurrent import LSTM\n",
        "visible = Input(shape=(100,1))\n",
        "hidden1 = LSTM(10)(visible)\n",
        "hidden2 = Dense(10, activation='relu')(hidden1)\n",
        "output = Dense(1, activation='sigmoid')(hidden2)\n",
        "model = Model(inputs=visible, outputs=output)\n",
        "# summarize layers\n",
        "model.summary()\n",
        "# plot graph\n",
        "plot_model(model, to_file='recurrent_neural_network.png')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 678
        },
        "id": "Tq4NYUk5GdHF",
        "outputId": "106dcd14-ce63-4cbf-ba9a-1ffd067bb81c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 100, 1)]          0         \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 10)                480       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                110       \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 601\n",
            "Trainable params: 601\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part III\n",
        "### Data Preparation\n",
        "\n",
        "\n",
        "- How to Clean Text Manually and with NLTK\n",
        "\n",
        "- How to Prepare Text Data with scikit-learn\n",
        "\n",
        "- How to Prepare Text Data With Keras"
      ],
      "metadata": {
        "id": "WTFwEySUJ0bO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### How to Clean Text Manually and with NLTK\n",
        "\n",
        "Text Cleaning Is Task Specific\n",
        "\n",
        "Take a moment to look at the text. What do you notice? Here's what I see:\n",
        "\n",
        "- It's plain text so there is no markup to parse (yay!).\n",
        "- The translation of the original German uses UK English (e.g. travelling).\n",
        "- The lines are artificially wrapped with new lines at about 70 characters (meh)\n",
        "- There are no obvious typos or spelling mistakes.\n",
        "- There's punctuation like commas, apostrophes, quotes, question marks, and more.\n",
        "- There's hyphenated descriptions like armour-like.\n",
        "- There's a lot of use of the em dash (-) to continue sentences (maybe replace with commas?).\n",
        "- There are names (e.g. Mr. Samsa)\n",
        "- There does not appear to be numbers that require handling (e.g. 1999)\n",
        "- There are section markers (e.g. II and III )."
      ],
      "metadata": {
        "id": "zyfz0axvKv_W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Manual Tokenization\n",
        "\n",
        "# Split by Whitespace\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "tCn0mKqcG3v3",
        "outputId": "aecc994e-c3e2-4918-afb2-51c7eff09423"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d14d0ace-2924-4b58-b7ec-88fb40432cf9\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d14d0ace-2924-4b58-b7ec-88fb40432cf9\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving metamorphosis_clean.txt to metamorphosis_clean.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load text\n",
        "filename = 'metamorphosis_clean.txt'\n",
        "file = open(filename, 'rt')\n",
        "text = file.read()\n",
        "\n",
        "file.close()\n",
        "# split into words by white space\n",
        "words = text.split()\n",
        "print(words[:100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRogIY7JQb29",
        "outputId": "14e8cc86-ab9f-46b8-fdcb-d8f4528b65c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['\\ufeffOne', 'morning,', 'when', 'Gregor', 'Samsa', 'woke', 'from', 'troubled', 'dreams,', 'he', 'found', 'himself', 'transformed', 'in', 'his', 'bed', 'into', 'a', 'horrible', 'vermin.', 'He', 'lay', 'on', 'his', 'armour-like', 'back,', 'and', 'if', 'he', 'lifted', 'his', 'head', 'a', 'little', 'he', 'could', 'see', 'his', 'brown', 'belly,', 'slightly', 'domed', 'and', 'divided', 'by', 'arches', 'into', 'stiff', 'sections.', 'The', 'bedding', 'was', 'hardly', 'able', 'to', 'cover', 'it', 'and', 'seemed', 'ready', 'to', 'slide', 'off', 'any', 'moment.', 'His', 'many', 'legs,', 'pitifully', 'thin', 'compared', 'with', 'the', 'size', 'of', 'the', 'rest', 'of', 'him,', 'waved', 'about', 'helplessly', 'as', 'he', 'looked.', '\"What\\'s', 'happened', 'to', 'me?\"', 'he', 'thought.', 'It', \"wasn't\", 'a', 'dream.', 'His', 'room,', 'a', 'proper', 'human']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Select Words\n",
        "\n",
        "# Another approach might be to use the regex model (re) and split the document into words by\n",
        "# selecting for strings of alphanumeric characters (a-z, A-Z, 0-9 and ` '). For example:\n",
        "\n",
        "import re\n",
        "# load text\n",
        "filename = 'metamorphosis_clean.txt'\n",
        "file = open(filename, 'rt')\n",
        "text = file.read()\n",
        "file.close()\n",
        "# split based on words only\n",
        "words = re.split(r'\\W+', text)\n",
        "print(words[:100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwXYBkS1Qq0r",
        "outputId": "00f32048-3157-475e-984c-5c117252ac1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['', 'One', 'morning', 'when', 'Gregor', 'Samsa', 'woke', 'from', 'troubled', 'dreams', 'he', 'found', 'himself', 'transformed', 'in', 'his', 'bed', 'into', 'a', 'horrible', 'vermin', 'He', 'lay', 'on', 'his', 'armour', 'like', 'back', 'and', 'if', 'he', 'lifted', 'his', 'head', 'a', 'little', 'he', 'could', 'see', 'his', 'brown', 'belly', 'slightly', 'domed', 'and', 'divided', 'by', 'arches', 'into', 'stiff', 'sections', 'The', 'bedding', 'was', 'hardly', 'able', 'to', 'cover', 'it', 'and', 'seemed', 'ready', 'to', 'slide', 'off', 'any', 'moment', 'His', 'many', 'legs', 'pitifully', 'thin', 'compared', 'with', 'the', 'size', 'of', 'the', 'rest', 'of', 'him', 'waved', 'about', 'helplessly', 'as', 'he', 'looked', 'What', 's', 'happened', 'to', 'me', 'he', 'thought', 'It', 'wasn', 't', 'a', 'dream', 'His']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split by Whitespace and Remove Punctuation\n",
        "\n",
        "import string\n",
        "\n",
        "print(string.punctuation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rX-epeRfRSaJ",
        "outputId": "f4130989-eb7e-409d-9bf4-23665f8aab8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We can use regular expressions to select for the punctuation characters and use the sub()\n",
        "# function to replace them with nothing. For example:\n",
        "\n",
        "re_punc = re.compile('[%s]' % re.escape(string.punctuation))\n",
        "# remove punctuation from each word\n",
        "stripped = [re_punc.sub('', w) for w in words]"
      ],
      "metadata": {
        "id": "4j57V3DKR78s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We can put all of this together, load the text file, split it into words by white space, then\n",
        "# translate each word to remove the punctuation.\n",
        "\n",
        "import string\n",
        "import re\n",
        "# load text\n",
        "filename = 'metamorphosis_clean.txt'\n",
        "file = open(filename, 'rt')\n",
        "text = file.read()\n",
        "file.close()\n",
        "# split into words by white space\n",
        "words = text.split()\n",
        "# prepare regex for char filtering\n",
        "re_punc = re.compile('[%s]' % re.escape(string.punctuation))\n",
        "# remove punctuation from each word\n",
        "stripped = [re_punc.sub('', w) for w in words]\n",
        "print(stripped[:100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xUnXC1JpSXvw",
        "outputId": "5e48ad0d-e2d1-4249-f69e-1aa94192b780"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['\\ufeffOne', 'morning', 'when', 'Gregor', 'Samsa', 'woke', 'from', 'troubled', 'dreams', 'he', 'found', 'himself', 'transformed', 'in', 'his', 'bed', 'into', 'a', 'horrible', 'vermin', 'He', 'lay', 'on', 'his', 'armourlike', 'back', 'and', 'if', 'he', 'lifted', 'his', 'head', 'a', 'little', 'he', 'could', 'see', 'his', 'brown', 'belly', 'slightly', 'domed', 'and', 'divided', 'by', 'arches', 'into', 'stiff', 'sections', 'The', 'bedding', 'was', 'hardly', 'able', 'to', 'cover', 'it', 'and', 'seemed', 'ready', 'to', 'slide', 'off', 'any', 'moment', 'His', 'many', 'legs', 'pitifully', 'thin', 'compared', 'with', 'the', 'size', 'of', 'the', 'rest', 'of', 'him', 'waved', 'about', 'helplessly', 'as', 'he', 'looked', 'Whats', 'happened', 'to', 'me', 'he', 'thought', 'It', 'wasnt', 'a', 'dream', 'His', 'room', 'a', 'proper', 'human']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sometimes text data may contain non-printable characters.\n",
        "\n",
        "re_print = re.compile('[^%s]' % re.escape(string.printable))\n",
        "result = [re_print.sub('', w) for w in words]\n",
        "print(result[:100])"
      ],
      "metadata": {
        "id": "qrfIX680SpkV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "100a36fa-3256-4f17-987f-dcd9b662ff60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['One', 'morning,', 'when', 'Gregor', 'Samsa', 'woke', 'from', 'troubled', 'dreams,', 'he', 'found', 'himself', 'transformed', 'in', 'his', 'bed', 'into', 'a', 'horrible', 'vermin.', 'He', 'lay', 'on', 'his', 'armour-like', 'back,', 'and', 'if', 'he', 'lifted', 'his', 'head', 'a', 'little', 'he', 'could', 'see', 'his', 'brown', 'belly,', 'slightly', 'domed', 'and', 'divided', 'by', 'arches', 'into', 'stiff', 'sections.', 'The', 'bedding', 'was', 'hardly', 'able', 'to', 'cover', 'it', 'and', 'seemed', 'ready', 'to', 'slide', 'off', 'any', 'moment.', 'His', 'many', 'legs,', 'pitifully', 'thin', 'compared', 'with', 'the', 'size', 'of', 'the', 'rest', 'of', 'him,', 'waved', 'about', 'helplessly', 'as', 'he', 'looked.', '\"What\\'s', 'happened', 'to', 'me?\"', 'he', 'thought.', 'It', \"wasn't\", 'a', 'dream.', 'His', 'room,', 'a', 'proper', 'human']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizing Case\n",
        "\n",
        "# We can convert all words to lowercase by calling the lower() function on each\n",
        "# word. For example:\n",
        "\n",
        "words = text.split()\n",
        "# convert to lower case\n",
        "words = [word.lower() for word in words]\n",
        "print(words[:100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3Z12moyTXnl",
        "outputId": "440e1c73-5dd0-4526-ea1d-7a2d56a6882b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['\\ufeffone', 'morning,', 'when', 'gregor', 'samsa', 'woke', 'from', 'troubled', 'dreams,', 'he', 'found', 'himself', 'transformed', 'in', 'his', 'bed', 'into', 'a', 'horrible', 'vermin.', 'he', 'lay', 'on', 'his', 'armour-like', 'back,', 'and', 'if', 'he', 'lifted', 'his', 'head', 'a', 'little', 'he', 'could', 'see', 'his', 'brown', 'belly,', 'slightly', 'domed', 'and', 'divided', 'by', 'arches', 'into', 'stiff', 'sections.', 'the', 'bedding', 'was', 'hardly', 'able', 'to', 'cover', 'it', 'and', 'seemed', 'ready', 'to', 'slide', 'off', 'any', 'moment.', 'his', 'many', 'legs,', 'pitifully', 'thin', 'compared', 'with', 'the', 'size', 'of', 'the', 'rest', 'of', 'him,', 'waved', 'about', 'helplessly', 'as', 'he', 'looked.', '\"what\\'s', 'happened', 'to', 'me?\"', 'he', 'thought.', 'it', \"wasn't\", 'a', 'dream.', 'his', 'room,', 'a', 'proper', 'human']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokenization and Cleaning with NLTK"
      ],
      "metadata": {
        "id": "HKUU5uroUFw1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "# nltk.download()"
      ],
      "metadata": {
        "id": "vTS5V_t9TsrA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NLTK script to split text into sentences.\n",
        "\n",
        "\n",
        "# nltk.download('punkt')\n",
        "from nltk import sent_tokenize\n",
        "# load data\n",
        "filename = 'metamorphosis_clean.txt'\n",
        "file = open(filename, 'rt')\n",
        "text = file.read()\n",
        "file.close()\n",
        "# split into sentences\n",
        "sentences = sent_tokenize(text)\n",
        "print(sentences[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8-vpR1c4J4-",
        "outputId": "5444fc06-1259-4b37-b35d-30ccca01e0a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "One morning, when Gregor Samsa woke from troubled dreams, he found\n",
            "himself transformed in his bed into a horrible vermin.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# NLTK script to split text into words.\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "# load data\n",
        "filename = 'metamorphosis_clean.txt'\n",
        "file = open(filename, 'rt')\n",
        "text = file.read()\n",
        "file.close()\n",
        "# split into words\n",
        "tokens = word_tokenize(text)\n",
        "print(tokens[:100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjEbdA5L4ma5",
        "outputId": "f42f8da1-9adb-4f79-dbf1-9ef4a27dadc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['\\ufeffOne', 'morning', ',', 'when', 'Gregor', 'Samsa', 'woke', 'from', 'troubled', 'dreams', ',', 'he', 'found', 'himself', 'transformed', 'in', 'his', 'bed', 'into', 'a', 'horrible', 'vermin', '.', 'He', 'lay', 'on', 'his', 'armour-like', 'back', ',', 'and', 'if', 'he', 'lifted', 'his', 'head', 'a', 'little', 'he', 'could', 'see', 'his', 'brown', 'belly', ',', 'slightly', 'domed', 'and', 'divided', 'by', 'arches', 'into', 'stiff', 'sections', '.', 'The', 'bedding', 'was', 'hardly', 'able', 'to', 'cover', 'it', 'and', 'seemed', 'ready', 'to', 'slide', 'off', 'any', 'moment', '.', 'His', 'many', 'legs', ',', 'pitifully', 'thin', 'compared', 'with', 'the', 'size', 'of', 'the', 'rest', 'of', 'him', ',', 'waved', 'about', 'helplessly', 'as', 'he', 'looked', '.', '``', 'What', \"'s\", 'happened', 'to']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# NLTK script to remove punctuation.\n",
        "\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "# load data\n",
        "filename = 'metamorphosis_clean.txt'\n",
        "file = open(filename, 'rt')\n",
        "text = file.read()\n",
        "file.close()\n",
        "# split into words\n",
        "tokens = word_tokenize(text)\n",
        "# remove all tokens that are not alphabetic\n",
        "words = [word for word in tokens if word.isalpha()]\n",
        "print(words[:100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqMiK5_E5Xy7",
        "outputId": "d202c362-13c7-48a1-ba5a-d5ae414a7293"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['morning', 'when', 'Gregor', 'Samsa', 'woke', 'from', 'troubled', 'dreams', 'he', 'found', 'himself', 'transformed', 'in', 'his', 'bed', 'into', 'a', 'horrible', 'vermin', 'He', 'lay', 'on', 'his', 'back', 'and', 'if', 'he', 'lifted', 'his', 'head', 'a', 'little', 'he', 'could', 'see', 'his', 'brown', 'belly', 'slightly', 'domed', 'and', 'divided', 'by', 'arches', 'into', 'stiff', 'sections', 'The', 'bedding', 'was', 'hardly', 'able', 'to', 'cover', 'it', 'and', 'seemed', 'ready', 'to', 'slide', 'off', 'any', 'moment', 'His', 'many', 'legs', 'pitifully', 'thin', 'compared', 'with', 'the', 'size', 'of', 'the', 'rest', 'of', 'him', 'waved', 'about', 'helplessly', 'as', 'he', 'looked', 'What', 'happened', 'to', 'me', 'he', 'thought', 'It', 'was', 'a', 'dream', 'His', 'room', 'a', 'proper', 'human', 'room', 'although']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter out Stop Words (and Pipeline)\n",
        "\n",
        "\n",
        "# nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = stopwords.words('english')\n",
        "print(stop_words)\n",
        "print(len(stop_words))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WaSLE21r52FT",
        "outputId": "2e1a5ceb-686e-4875-b5b3-2efa8e066cae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
            "179\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stop Words:\n",
        "\n",
        "You can see that they are all lower case and have punctuation removed. \n",
        "\n",
        "You could compare\n",
        "your tokens to the stop words and filter them out, but you must ensure that your text is prepared\n",
        "the same way. \n",
        "\n",
        "Let's demonstrate this with a small pipeline of text preparation including:\n",
        "-  Load the raw text.\n",
        "-  Split into tokens.\n",
        "-  Convert to lowercase.\n",
        "-  Remove punctuation from each token.\n",
        "-  Filter out remaining tokens that are not alphabetic.\n",
        "-  Filter out tokens that are stop words."
      ],
      "metadata": {
        "id": "FAh0M0A46npy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "import re\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "# load data\n",
        "filename = 'metamorphosis_clean.txt'\n",
        "file = open(filename, 'rt')\n",
        "text = file.read()\n",
        "file.close()\n",
        "# split into words\n",
        "tokens = word_tokenize(text)\n",
        "# convert to lower case\n",
        "tokens = [w.lower() for w in tokens]\n",
        "# prepare regex for char filtering\n",
        "re_punc = re.compile('[%s]' % re.escape(string.punctuation))\n",
        "# remove punctuation from each word\n",
        "stripped = [re_punc.sub('', w) for w in tokens]\n",
        "# remove remaining tokens that are not alphabetic\n",
        "words = [word for word in stripped if word.isalpha()]\n",
        "# filter out stop words\n",
        "stop_words = set(stopwords.words('english'))\n",
        "words = [w for w in words if not w in stop_words]\n",
        "print(words[:100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tR5SqrQq6MCt",
        "outputId": "d83aaee0-646e-4509-a3d3-fef0893f1ed2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['morning', 'gregor', 'samsa', 'woke', 'troubled', 'dreams', 'found', 'transformed', 'bed', 'horrible', 'vermin', 'lay', 'armourlike', 'back', 'lifted', 'head', 'little', 'could', 'see', 'brown', 'belly', 'slightly', 'domed', 'divided', 'arches', 'stiff', 'sections', 'bedding', 'hardly', 'able', 'cover', 'seemed', 'ready', 'slide', 'moment', 'many', 'legs', 'pitifully', 'thin', 'compared', 'size', 'rest', 'waved', 'helplessly', 'looked', 'happened', 'thought', 'nt', 'dream', 'room', 'proper', 'human', 'room', 'although', 'little', 'small', 'lay', 'peacefully', 'four', 'familiar', 'walls', 'collection', 'textile', 'samples', 'lay', 'spread', 'table', 'samsa', 'travelling', 'salesman', 'hung', 'picture', 'recently', 'cut', 'illustrated', 'magazine', 'housed', 'nice', 'gilded', 'frame', 'showed', 'lady', 'fitted', 'fur', 'hat', 'fur', 'boa', 'sat', 'upright', 'raising', 'heavy', 'fur', 'muff', 'covered', 'whole', 'lower', 'arm', 'towards', 'viewer', 'gregor']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Running this example, we can see that in addition to all of the other transforms, stop words\n",
        "like a and to have been removed. I note that we are still left with tokens like *nt*. The rabbit\n",
        "hole is deep; there's always more we can do."
      ],
      "metadata": {
        "id": "o0rU1YSu7jwI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stem Words\n",
        "\n",
        "Stemming refers to the process of reducing each word to its root or base. For example *fishing,\n",
        "fished, fisher* all reduce to the stem **fish**.\n",
        "\n",
        "There are many stemming algorithms,\n",
        "although a popular and long-standing method is the *Porter Stemming* algorithm. This method\n",
        "is available in NLTK via the *PorterStemmer* class."
      ],
      "metadata": {
        "id": "LzsKlBLm7yRl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# NLTK script stem words.\n",
        "# the stemming implementation has also reduced\n",
        "# the tokens to lowercase, likely for internal look-ups in word tables.\n",
        "\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "# load data\n",
        "filename = 'metamorphosis_clean.txt'\n",
        "file = open(filename, 'rt')\n",
        "text = file.read()\n",
        "file.close()\n",
        "# split into words\n",
        "tokens = word_tokenize(text)\n",
        "# stemming of words\n",
        "porter = PorterStemmer()\n",
        "stemmed = [porter.stem(word) for word in tokens]\n",
        "print(stemmed[:100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8JSZLLu37WlY",
        "outputId": "753cc95a-db44-4248-b993-561dde3b5fa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['\\ufeffone', 'morn', ',', 'when', 'gregor', 'samsa', 'woke', 'from', 'troubl', 'dream', ',', 'he', 'found', 'himself', 'transform', 'in', 'hi', 'bed', 'into', 'a', 'horribl', 'vermin', '.', 'He', 'lay', 'on', 'hi', 'armour-lik', 'back', ',', 'and', 'if', 'he', 'lift', 'hi', 'head', 'a', 'littl', 'he', 'could', 'see', 'hi', 'brown', 'belli', ',', 'slightli', 'dome', 'and', 'divid', 'by', 'arch', 'into', 'stiff', 'section', '.', 'the', 'bed', 'wa', 'hardli', 'abl', 'to', 'cover', 'it', 'and', 'seem', 'readi', 'to', 'slide', 'off', 'ani', 'moment', '.', 'hi', 'mani', 'leg', ',', 'piti', 'thin', 'compar', 'with', 'the', 'size', 'of', 'the', 'rest', 'of', 'him', ',', 'wave', 'about', 'helplessli', 'as', 'he', 'look', '.', '``', 'what', \"'s\", 'happen', 'to']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Additional Text Cleaning Considerations\n",
        "\n",
        "Here is a shortlist of additional considerations when cleaning text:\n",
        "-  Handling large documents and large collections of text documents that do not fit into\n",
        "memory.\n",
        "-  Extracting text from markup like HTML, PDF, or other structured document formats.\n",
        "-  Transliteration of characters from other languages into English.\n",
        "-  Decoding Unicode characters into a normalized form, such as UTF8.\n",
        "-  Handling of domain specific words, phrases, and acronyms.\n",
        "-  Handling or removing numbers, such as dates and amounts.\n",
        "-  Locating and correcting common typos and misspellings."
      ],
      "metadata": {
        "id": "EzjocET19xxA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### How to Prepare Text Data with scikit-learn\n",
        "\n",
        "After completing this tutorial, you will know:\n",
        "-  How to convert text to word count vectors with *CountVectorizer.*\n",
        "-  How to convert text to word frequency vectors with *TfidfVectorizer.*\n",
        "-  How to convert text to unique integers with *HashingVectorizer.*"
      ],
      "metadata": {
        "id": "pcNdxGTF-RTT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Bag-of-Words Model\n",
        "\n",
        "The model is simple in that it throws away all of the order\n",
        "information in the words and focuses on the occurrence of words in a document.\n",
        "\n",
        "This can be done by assigning each word a unique number.\n",
        "\n",
        "Then any document we see can be encoded\n",
        "as a fixed-length vector with the length of the vocabulary of known words. \n",
        "\n",
        "The value in each position in the vector could be filled with a count or frequency of each word in the encoded\n",
        "document."
      ],
      "metadata": {
        "id": "ZWD7JyBh_ZWg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The scikit-learn library provides 3 different schemes that we can use, and we will briefly look at each.\n",
        "\n",
        "- Word Counts with **CountVectorizer**\n",
        "\n",
        "The CountVectorizer provides a simple way to both tokenize a collection of text documents\n",
        "and build a vocabulary of known words, but also to encode new documents using that vocabulary.\n",
        "\n",
        "An encoded vector is returned with a length of the entire vocabulary and an integer count for the number of times each word appeared in the document. \n",
        "\n",
        "Because these vectors will\n",
        "contain a lot of zeros, we call them sparse. Python provides an efficient way of handling sparse vectors in the scipy.sparse package. \n",
        "\n",
        "The vectors returned from a call to transform() will\n",
        "be sparse vectors, and you can transform them back to NumPy arrays to look and better understand what is going on by calling the toarray() function. \n",
        "\n",
        "Below is an example of using\n",
        "the CountVectorizer to tokenize, build a vocabulary, and then encode a document.\n"
      ],
      "metadata": {
        "id": "a2XGMqBMARtX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "# list of text documents\n",
        "text = [\"The quick brown fox jumped over the lazy dog.\"]\n",
        "# create the transform\n",
        "vectorizer = CountVectorizer()\n",
        "# tokenize and build vocab\n",
        "vectorizer.fit(text)\n",
        "# summarize\n",
        "print(vectorizer.vocabulary_)\n",
        "# encode document\n",
        "vector = vectorizer.transform(text)\n",
        "# summarize encoded vector\n",
        "print('\\nshape of the encoded document: ',vector.shape)\n",
        "print(type(vector))\n",
        "print()\n",
        "print('sparse vector:\\n',vector)\n",
        "print()\n",
        "print(vector.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ym9qzGiI8kC0",
        "outputId": "3c0f936e-04f3-4286-b364-794b1ae34d82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'the': 7, 'quick': 6, 'brown': 0, 'fox': 2, 'jumped': 3, 'over': 5, 'lazy': 4, 'dog': 1}\n",
            "\n",
            "shape of the encoded document:  (1, 8)\n",
            "<class 'scipy.sparse.csr.csr_matrix'>\n",
            "\n",
            "sparse vector:\n",
            "   (0, 0)\t1\n",
            "  (0, 1)\t1\n",
            "  (0, 2)\t1\n",
            "  (0, 3)\t1\n",
            "  (0, 4)\t1\n",
            "  (0, 5)\t1\n",
            "  (0, 6)\t1\n",
            "  (0, 7)\t2\n",
            "\n",
            "[[1 1 1 1 1 1 1 2]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importantly, the same vectorizer can be used on documents that contain words not included\n",
        "# in the vocabulary.\n",
        "\n",
        "\n",
        "# encode another document\n",
        "text2 = [\"the puppy\"]\n",
        "vector = vectorizer.transform(text2)\n",
        "print(vector.toarray())\n",
        "\n",
        "\n",
        "# The encoded vectors can then be used directly with a machine learning algorithm."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JxfzawNnBQyT",
        "outputId": "d2a4f1c1-c976-4e71-c98d-b770cb47a052"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0 0 0 0 0 0 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Word Frequencies with TfidfVectorizer**\n",
        "\n",
        "Without going into the math, TF-IDF are word frequency scores that try to highlight\n",
        "words that are more interesting, e.g. frequent in a document but not across documents.\n",
        "\n",
        "- Term Frequency (tf): This summarizes how often a given word appears within a document.\n",
        "- Inverse Document Frequency (idf): This downscales words that appear a lot across documents.\n",
        "\n",
        "The TfidfVectorizer will tokenize documents, learn the vocabulary and inverse document frequency weightings, and allow you to encode new documents.\n",
        "\n",
        "Alternately, if you already have a\n",
        "learned *CountVectorizer*, you can use it with a **TfidfTransformer** to just calculate the inverse\n",
        "document frequencies and start encoding documents."
      ],
      "metadata": {
        "id": "j9ut0sxJDX5o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# list of text documents\n",
        "text = [\"The quick brown fox jumped over the lazy dog.\",\n",
        "\"The dog.\",\n",
        "\"The fox\"]\n",
        "# create the transform\n",
        "vectorizer = TfidfVectorizer()\n",
        "# tokenize and build vocab\n",
        "vectorizer.fit(text)\n",
        "# summarize\n",
        "print(vectorizer.vocabulary_)\n",
        "print('\\ntf_idf vector:\\n',vectorizer.idf_)\n",
        "\n",
        "# encode document, the first text\n",
        "vector = vectorizer.transform([text[0]])\n",
        "\n",
        "# summarize encoded vector\n",
        "print('\\nvector shape: ', vector.shape)\n",
        "print(vector.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xV6w2rloC8dH",
        "outputId": "2cf1646d-93a4-4a1c-a3e1-d9049db4c936"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'the': 7, 'quick': 6, 'brown': 0, 'fox': 2, 'jumped': 3, 'over': 5, 'lazy': 4, 'dog': 1}\n",
            "\n",
            "tf_idf vector:\n",
            " [1.69314718 1.28768207 1.28768207 1.69314718 1.69314718 1.69314718\n",
            " 1.69314718 1.        ]\n",
            "\n",
            "vector shape:  (1, 8)\n",
            "[[0.36388646 0.27674503 0.27674503 0.36388646 0.36388646 0.36388646\n",
            "  0.36388646 0.42983441]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Hashing with HashingVectorizer\n",
        "\n",
        "Counts and frequencies can be very useful, but one limitation of these methods is that the vocabulary can become very large. This, in turn, will require large vectors for encoding\n",
        "documents and impose large requirements on memory and slow down algorithms. \n",
        "\n",
        "A clever work\n",
        "around is to use a one way hash of words to convert them to integers. \n",
        "\n",
        "The clever part is that\n",
        "no vocabulary is required and you can choose an arbitrary-long fixed length vector.\n",
        "\n",
        "A downside is that the hash is a one-way function so there is no way to convert the encoding back to a word\n",
        "(which may not matter for many supervised learning tasks).\n",
        "\n",
        "\n",
        "The values\n",
        "of the encoded document correspond to normalized word counts by default in the range of -1 to 1, but could be made simple integer counts by changing the default configuration."
      ],
      "metadata": {
        "id": "B6KYMM72GQ51"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import HashingVectorizer\n",
        "# list of text documents\n",
        "text = [\"The quick brown fox jumped over the lazy dog.\"]\n",
        "# create the transform\n",
        "vectorizer = HashingVectorizer(n_features=20)\n",
        "# encode document\n",
        "vector = vectorizer.transform(text)\n",
        "# summarize encoded vector\n",
        "print(vector.shape)\n",
        "print(vector.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fd-Dcft4EyBQ",
        "outputId": "15417549-dafc-4b27-d993-2b5113b06bb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 20)\n",
            "[[ 0.          0.          0.          0.          0.          0.33333333\n",
            "   0.         -0.33333333  0.33333333  0.          0.          0.33333333\n",
            "   0.          0.          0.         -0.33333333  0.          0.\n",
            "  -0.66666667  0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### How to Prepare Text Data With Keras"
      ],
      "metadata": {
        "id": "V9qSyWeiKEYf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Keras deep learning library provides some basic tools to help you\n",
        "prepare your text data. \n",
        "\n",
        "In this tutorial, you will discover how you can use Keras to prepare\n",
        "your text data.\n",
        "\n",
        "- About the convenience methods that you can use to quickly prepare text data.\n",
        "- The Tokenizer API that can be fit on training data and used to encode training, validation,\n",
        "and test documents.\n",
        "- The range of 4 different document encoding schemes o\u000bered by the Tokenizer API.\n",
        "\n",
        "**Split Words with text to word sequence**\n",
        "\n",
        "Keras provides the\n",
        "text to word sequence() function that you can use to split text into a list of words. \n",
        "\n",
        "By default, this function automatically does 3 things:\n",
        "\n",
        "- Splits words by space.\n",
        "- Filters out punctuation.\n",
        "- Converts text to lowercase (lower=True).\n",
        "\n",
        "You can change any of these defaults by passing arguments to the function.\n",
        "\n"
      ],
      "metadata": {
        "id": "0vnO0pcaK2RU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import text_to_word_sequence\n",
        "# define the document\n",
        "text = 'The quick brown fox jumped over the lazy dog.'\n",
        "# tokenize the document\n",
        "result = text_to_word_sequence(text)\n",
        "print(result)"
      ],
      "metadata": {
        "id": "XxeK9CFNH-M7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c68e320-29ec-4133-bed0-558de0a6d6f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['the', 'quick', 'brown', 'fox', 'jumped', 'over', 'the', 'lazy', 'dog']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Encoding with one hot**\n",
        "\n",
        "In addition to the text, the vocabulary size (total words) must be specified. \n",
        "\n",
        "This could be the\n",
        "total number of words in the document or more if you intend to encode additional documents\n",
        "that contains additional words.\n",
        "\n",
        "We can use the text to word sequence() function from the previous section to split the\n",
        "document into words and then use a set to represent only the unique words in the document."
      ],
      "metadata": {
        "id": "0UBtcPlkLp8o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Note: Given the stochastic nature of neural networks, your specific results may vary. Consider\n",
        "# running the example a few times.\n",
        "\n",
        "# Example of one hot encoding.\n",
        "\n",
        "from keras.preprocessing.text import one_hot\n",
        "from keras.preprocessing.text import text_to_word_sequence\n",
        "# define the document\n",
        "text = 'The quick brown fox jumped over the lazy dog.'\n",
        "# estimate the size of the vocabulary\n",
        "words = set(text_to_word_sequence(text))\n",
        "vocab_size = len(words)\n",
        "print(vocab_size)\n",
        "# integer encode the document\n",
        "result = one_hot(text, round(vocab_size*1.3))\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNlDUlhnLmNP",
        "outputId": "7d248227-7fbc-4a82-c47a-5846b603ce2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8\n",
            "[7, 7, 8, 5, 8, 7, 7, 8, 4]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hash Encoding with hashing trick**\n",
        "\n",
        "A limitation of integer and count base encodings is that they must maintain a vocabulary of\n",
        "words and their mapping to integers. \n",
        "\n",
        "An alternative to this approach is to use a one-way hash\n",
        "function to convert words to integers. \n",
        "\n",
        "This avoids the need to keep track of a vocabulary, which\n",
        "is faster and requires less memory.\n",
        "\n"
      ],
      "metadata": {
        "id": "_Rkf6zoIMUoC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of hash encoding.\n",
        "\n",
        "from keras.preprocessing.text import hashing_trick\n",
        "from keras.preprocessing.text import text_to_word_sequence\n",
        "# define the document\n",
        "text = 'The quick brown fox jumped over the lazy dog.'\n",
        "# estimate the size of the vocabulary\n",
        "words = set(text_to_word_sequence(text))\n",
        "vocab_size = len(words)\n",
        "print(vocab_size)\n",
        "# integer encode the document\n",
        "result = hashing_trick(text, round(vocab_size*1.3), hash_function='md5')\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmrvXJc2MSgR",
        "outputId": "578ee5bc-fc8d-41e1-fa14-56f406e3c899"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8\n",
            "[6, 4, 1, 2, 7, 5, 6, 2, 6]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tokenizer API**\n",
        "\n",
        "\n",
        "Keras provides a more sophisticated API for preparing text that can be fit and reused to prepare multiple text documents.\n",
        "\n",
        "This may be the preferred approach for large projects. \n",
        "\n",
        "Keras provides\n",
        "the Tokenizer class for preparing text documents for deep learning. \n",
        "\n",
        "The Tokenizer must be constructed and then fit on either raw text documents or integer encoded text documents.\n",
        "\n"
      ],
      "metadata": {
        "id": "-uQqZf8eNKSM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "# define 5 documents\n",
        "docs = ['Well done!',\n",
        "'Good work',\n",
        "'Great effort',\n",
        "'nice work',\n",
        "'Excellent!']\n",
        "# create the tokenizer\n",
        "t = Tokenizer()\n",
        "# fit the tokenizer on the documents\n",
        "t.fit_on_texts(docs)"
      ],
      "metadata": {
        "id": "YAuDsaXANizp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once fit, the Tokenizer provides 4 attributes that you can use to query what has been\n",
        "learned about your documents:\n",
        "- word counts: A dictionary mapping of words and their occurrence counts when the Tokenizer was fit.\n",
        "- word docs: A dictionary mapping of words and the number of documents that reach appears in.\n",
        "- word index: A dictionary of words and their uniquely assigned integers.\n",
        "- document count: A dictionary mapping and the number of documents they appear in calculated during the fit."
      ],
      "metadata": {
        "id": "Xt_0kvK9NngZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize what was learned\n",
        "print('word_counts:\\n', t.word_counts)\n",
        "print('\\ndocument_count:\\n',t.document_count)\n",
        "print('\\n\\nword_index:\\n',t.word_index)\n",
        "print('\\nword_docs:\\n',t.word_docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OdGdo0_SNGiJ",
        "outputId": "be0a52b3-d7e1-4156-fd9c-a42db6c77b25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "word_counts:\n",
            " OrderedDict([('well', 1), ('done', 1), ('good', 1), ('work', 2), ('great', 1), ('effort', 1), ('nice', 1), ('excellent', 1)])\n",
            "\n",
            "document_count:\n",
            " 5\n",
            "\n",
            "\n",
            "word_index:\n",
            " {'work': 1, 'well': 2, 'done': 3, 'good': 4, 'great': 5, 'effort': 6, 'nice': 7, 'excellent': 8}\n",
            "\n",
            "word_docs:\n",
            " defaultdict(<class 'int'>, {'done': 1, 'well': 1, 'good': 1, 'work': 2, 'effort': 1, 'great': 1, 'nice': 1, 'excellent': 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once the Tokenizer has been fit on training data, it can be used to encode documents in\n",
        "the train or test datasets. \n",
        "\n",
        "The *texts_to_matrix()* function on the *Tokenizer* can be used to\n",
        "create one vector per document provided per input. \n",
        "\n",
        "The length of the vectors is the total size\n",
        "of the vocabulary. \n",
        "\n",
        "This function provides a suite of standard bag-of-words model text encoding\n",
        "schemes that can be provided via a mode argument to the function.\n",
        "\n",
        "The modes available include:\n",
        "- **binary**: Whether or not each word is present in the document. This is the **default**.\n",
        "- **count**: The count of each word in the document.\n",
        "- **tfidf**: The Text Frequency-Inverse DocumentFrequency (TF-IDF) scoring for each word in the document.\n",
        "- **freq**: The frequency of each word as a ratio of words within each document.\n",
        "\n",
        "**The Tokenizer will be the key way we will prepare text for word embeddings throughout this book.**"
      ],
      "metadata": {
        "id": "z6Q6sMI7OUUn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We can put all of this together with a worked example.\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "# define 5 documents\n",
        "docs = ['Well done!',\n",
        "'Good work',\n",
        "'Great effort',\n",
        "'nice work',\n",
        "'Excellent!']\n",
        "# create the tokenizer\n",
        "t = Tokenizer()\n",
        "# fit the tokenizer on the documents\n",
        "t.fit_on_texts(docs)\n",
        "# summarize what was learned\n",
        "print(t.word_counts)\n",
        "print(t.document_count)\n",
        "print(t.word_index)\n",
        "print(t.word_docs)\n",
        "# integer encode documents\n",
        "encoded_docs = t.texts_to_matrix(docs, mode='count')\n",
        "print('\\n\\ntexts_to_matrix:\\n',encoded_docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXvkc0foOL7g",
        "outputId": "daca4a90-a1f2-407e-b14a-5bff4590e229"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OrderedDict([('well', 1), ('done', 1), ('good', 1), ('work', 2), ('great', 1), ('effort', 1), ('nice', 1), ('excellent', 1)])\n",
            "5\n",
            "{'work': 1, 'well': 2, 'done': 3, 'good': 4, 'great': 5, 'effort': 6, 'nice': 7, 'excellent': 8}\n",
            "defaultdict(<class 'int'>, {'done': 1, 'well': 1, 'good': 1, 'work': 2, 'effort': 1, 'great': 1, 'nice': 1, 'excellent': 1})\n",
            "\n",
            "\n",
            "texts_to_matrix:\n",
            " [[0. 0. 1. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part IV Bag-of-Words"
      ],
      "metadata": {
        "id": "hAX2Qg7UKonM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The bag-of-words model is a way of representing text data when modeling text with machine learning algorithms.\n",
        "\n",
        "In this\n",
        "tutorial, you will discover the bag-of-words model for feature extraction in natural language\n",
        "processing. \n",
        "\n",
        "After completing this tutorial, you will know:\n",
        "- What the bag-of-words model is and why it is needed to represent text.\n",
        "- How to develop a bag-of-words model for a collection of documents.\n",
        "- How to use di\u000berent techniques to prepare a vocabulary and score words.\n",
        "\n",
        "Machine learning algorithms cannot work\n",
        "with raw text directly; the text must be converted into numbers. \n",
        "\n",
        "Specifically, vectors of numbers.\n",
        "\n",
        "*In language processing, the vectors x are derived from textual data, in order to reflect various linguistic properties of the text.*\n",
        "\n",
        "This is called feature extraction or feature encoding. \n",
        "\n",
        "A popular and simple method of feature extraction with text data is called the bag-of-words model of text.\n",
        "\n",
        "The approach is very simple and \n",
        "flexible, and can be used in a myriad of ways for extracting features from documents. \n",
        "\n",
        "A bag-of-words is a representation of text that describes the occurrence of words within a document. \n",
        "\n",
        "It involves two things:\n",
        "- A vocabulary of known words.\n",
        "- A measure of the presence of known words.\n",
        "\n",
        "It is called a bag-of-words , because any information about the order or structure of words in the document is discarded. \n",
        "\n",
        "The model is only concerned with whether known words **occur** in\n",
        "the document, **not where** in the document."
      ],
      "metadata": {
        "id": "WobS0Tw6QhdC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*A very common feature extraction procedures for sentences and documents is the bag-of-words approach (BOW). In this approach, we look at the histogram of the\n",
        "words within the text, i.e. considering each word count as a feature.*\n",
        "\n",
        "The bag-of-words can be as simple or complex as you like. \n",
        "\n",
        "The complexity comes both in deciding how to design\n",
        "the vocabulary of known words (or tokens) and how to score the presence of known words.\n",
        "\n"
      ],
      "metadata": {
        "id": "SI_1NKvQT9YJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example of the Bag-of-Words Model**\n",
        "\n",
        "Sample of text from A Tale of Two Cities by Charles Dickens.\n",
        "\n",
        "It was the best of times,\n",
        "\n",
        "it was the worst of times,\n",
        "\n",
        "it was the age of wisdom,\n",
        "\n",
        "it was the age of foolishness,\n",
        "\n",
        "For this small example, let's treat each line as a separate document and the 4 lines as our entire corpus of documents.\n",
        "\n",
        "**list of all of the words in our model vocabulary.**\n",
        "- it\n",
        "- was\n",
        "- the\n",
        "- best\n",
        "- of\n",
        "- times\n",
        "- worst\n",
        "- age\n",
        "- wisdom\n",
        "- foolishness\n",
        "\n",
        "That is a vocabulary of 10 words from a corpus containing 24 words."
      ],
      "metadata": {
        "id": "SSxH4EhnUsI3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create Document Vectors**\n",
        "\n",
        "Because\n",
        "we know the vocabulary has 10 words, we can use a fixed-length document representation of 10, with one position in the vector to score each word. \n",
        "\n",
        "The simplest scoring method is to mark the\n",
        "presence of words as a boolean value, 0 for absent, 1 for present.\n",
        "\n",
        "first document (It was the best of times) and convert it into a binary vector. The scoring of the document would look as follows:\n",
        "\n",
        "- it = 1\n",
        "-was = 1\n",
        "-the = 1\n",
        "-best = 1\n",
        "-of = 1\n",
        "-times = 1\n",
        "-worst = 0\n",
        "-age = 0\n",
        "-wisdom = 0\n",
        "-foolishness = 0\n",
        "\n",
        "As a binary vector, this would look as follows:\n",
        "\n",
        "[1, 1, 1, 1, 1, 1, 0, 0, 0, 0]\n",
        "\n",
        "The other three documents would look as follows:\n",
        "\n",
        "- \"it was the worst of times\" = [1, 1, 1, 0, 1, 1, 1, 0, 0, 0]\n",
        "- \"it was the age of wisdom\" = [1, 1, 1, 0, 1, 0, 0, 1, 1, 0]\n",
        "- \"it was the age of foolishness\" = [1, 1, 1, 0, 1, 0, 0, 1, 0, 1]\n",
        "\n",
        "New documents that\n",
        "overlap with the vocabulary of known words, but may contain words outside of the vocabulary, can still be encoded, where only the **occurrence of known words** are scored and unknown words are ignored."
      ],
      "metadata": {
        "id": "XkyOpoISVbXx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Managing Vocabulary**\n",
        "\n",
        "You can\n",
        "imagine that for a very large corpus, such as thousands of books, that the length of the vector\n",
        "might be thousands or millions of positions. Further, each document may contain very few of the known words in the vocabulary.\n",
        "\n",
        "This results in a vector with lots of zero scores, called a sparse vector or sparse representation.\n",
        "\n",
        "Sparse vectors require more memory and computational resources when modeling and the vast number of positions or dimensions can make the modeling process very challenging for traditional algorithms. \n",
        "\n",
        "As such, there is pressure to decrease the size of the vocabulary when\n",
        "using a bag-of-words model.\n",
        "\n",
        "There are simple text cleaning techniques that can be used as a first step, such as:\n",
        "\n",
        "- Ignoring case.\n",
        "- Ignoring punctuation.\n",
        "- Ignoring frequent words that don't contain much information, called **stop words**, like a, of, etc.\n",
        "- Fixing misspelled words.\n",
        "- Reducing words to their stem (e.g. play from playing) using stemming algorithms.\n",
        "\n",
        "-----------------------------------------\n",
        "A more sophisticated approach is to create a vocabulary of grouped words. This both\n",
        "changes the scope of the vocabulary and allows the bag-of-words to capture a little bit more\n",
        "meaning from the document. \n",
        "\n",
        "In this approach, each word or token is called a *gram*. \n",
        "\n",
        "Creating a vocabulary of *two-word pairs* is, in turn, called a *bigram* model. \n",
        "\n",
        "Again, only the bigrams that\n",
        "appear in the corpus are modeled, not all possible bigrams.\n",
        "\n",
        "An n-gram is an n-token sequence of words: a 2-gram (more commonly called a\n",
        "bigram) is a two-word sequence of words like \\please turn\", \\turn your\", or \\your homework\", and a 3-gram (more commonly called a **trigram**) is a three-word sequence of words like \\please turn your\", or \\turn your homework\".\n",
        "- \n",
        "Often a simple\n",
        "bigram approach is better than a 1-gram bag-of-words model for tasks like documentation\n",
        "classification."
      ],
      "metadata": {
        "id": "xw6NIj5NXxUX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Scoring Words**\n",
        "\n",
        "\n",
        "- Word Hashing\n",
        "Words are hashed deterministically to the same integer index in the target hash space. A binary score or count can then be used to score the word. \n",
        "\n",
        "    This is called the hash trick or feature\n",
        "    hashing. \n",
        "\n",
        "    The challenge is to choose a hash space to accommodate the chosen vocabulary size to minimize the probability of collisions and trade-of sparsity.\n",
        "\n",
        "- TF-IDF\n",
        "    \n",
        "    **Term Frequency (TF)**: is a scoring of the frequency of the word in the current document.\n",
        "    \n",
        "    **Inverse Document Frequency (IDF)**: is a scoring of how rare the word is across documents.\n",
        "    \n",
        "    The scores are a weighting where not all words are equally as important or interesting. \n",
        "    \n",
        "    The scores have the e\u000bect of highlighting words that are distinct (contain useful information) in a given document."
      ],
      "metadata": {
        "id": "G_86OSeCaRFp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Limitations of Bag-of-Words**\n",
        "\n",
        "The bag-of-words model is very simple to understand and implement and offers a lot of exibility for customization on your specific text data. \n",
        "\n",
        "It has been used with great success on prediction\n",
        "problems like language modeling and documentation classification. \n",
        "\n",
        "Nevertheless, it suffers from some shortcomings, such as:\n",
        "\n",
        "- **Vocabulary**: The vocabulary requires careful design, most specifically in order to manage\n",
        "the size, which impacts the sparsity of the document representations.\n",
        "\n",
        "- **Sparsity**: Sparse representations are harder to model both for computational reasons\n",
        "(space and time complexity) and also for information reasons, where the challenge is for\n",
        "the models to harness so little information in such a large representational space.\n",
        "\n",
        "- **Meaning**: Discarding word order ignores the context, and in turn meaning of words in\n",
        "the document (semantics). Context and meaning can offer a lot to the model, that if\n",
        "modeled could tell the difference between the same words differently arranged (this is interesting vs is this interesting), synonyms (old bike vs used bike), and much more."
      ],
      "metadata": {
        "id": "6Cx4f8gEcQ07"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **How to Prepare Movie Review Data for Sentiment Analysis**\n",
        "\n",
        "**Text data preparation is di\u000berent for each problem.**\n",
        "\n",
        "Preparation starts with simple steps, like\n",
        "loading data, but quickly gets di\u000ecult with cleaning tasks that are very specific to the data you\n",
        "are working with. \n",
        "\n",
        "You need help as to where to begin and what order to work through the steps\n",
        "from raw data to data ready for modeling. \n",
        "\n",
        "In this tutorial, you will discover how to prepare\n",
        "movie review text data for sentiment analysis, step-by-step. \n",
        "\n",
        "After completing this tutorial, you will know:\n",
        "- How to load text data and clean it to remove punctuation and other non-words.\n",
        "- How to develop a vocabulary, tailor it, and save it to file.\n",
        "- How to prepare movie reviews using cleaning and a pre-defined vocabulary and save them to new files ready for modeling.\n",
        "\n",
        "This tutorial is divided into the following parts:\n",
        "1. Movie Review Dataset\n",
        "2. Load Text Data\n",
        "3. Clean Text Data\n",
        "4. Develop Vocabulary\n",
        "5. Save Prepared Data\n",
        "\n",
        "Our data contains 1000 positive and 1000 negative reviews all written before 2002,\n",
        "with a cap of 20 reviews per author (312 authors total) per category. We refer to this corpus as the polarity dataset.\n",
        "\n",
        "The data has been cleaned up somewhat, for example:\n",
        "- The dataset is comprised of only English reviews.\n",
        "- All text has been converted to lowercase.\n",
        "- There is white space around punctuation like periods, commas, and brackets.\n",
        "- Text has been split into one sentence per line."
      ],
      "metadata": {
        "id": "MdnyjSomr73n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')     # Mounting Google Drive in Colab"
      ],
      "metadata": {
        "id": "gITI5xVPQCoG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6273ebee-fb77-40a5-d46e-90a54e1f549b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the reading of the file from Drive\n",
        "\n",
        "with open('/content/gdrive/My Drive/txt_sentoken/neg/cv000_29416.txt', 'r') as f:\n",
        "    text_neg = f.read()\n",
        "# print(text_neg)"
      ],
      "metadata": {
        "id": "cCtd6AttKrdz"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We can turn this into a function called load doc() that takes a filename of the document to load and\n",
        "# returns the text.\n",
        "\n",
        "def load_doc(filename):\n",
        "    # open the file as read only\n",
        "    with open(filename, 'r') as f:\n",
        "        text = f.read()\n",
        "    # close the file\n",
        "    file.close()\n",
        "    return text"
      ],
      "metadata": {
        "id": "_ZHgnDRuBWmt"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%capture   ------------------------->>>   to hide the cell output\n",
        "\n",
        "# We have two directories each with 1,000 documents each. We can process each directory in\n",
        "# turn by first getting a list of files in the directory using the listdir() function, then loading\n",
        "# each file in turn.\n",
        "\n",
        "\n",
        "def load_doc(filename):\n",
        "    # open the file as read only\n",
        "    with open(filename, 'r') as f:\n",
        "        text = f.read()\n",
        "    # close the file\n",
        "    file.close()\n",
        "    return text\n",
        "\n",
        "# specify directory in Google Drive to load in Colab\n",
        "directory = '/content/gdrive/My Drive/txt_sentoken/neg'\n",
        "\n",
        "from os import listdir\n",
        "\n",
        "# walk through all files in the folder\n",
        "i= 0 \n",
        "for filename in listdir(directory):\n",
        "    # skip files that do not have the right extension\n",
        "    if not filename.endswith(\".txt\"):\n",
        "        next\n",
        "    # create the full path of the file to open\n",
        "    path = directory + '/' + filename\n",
        "    # load document\n",
        "    doc = load_doc(path)\n",
        "    i += 1\n",
        "    print(i, 'Loaded %s' % filename)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMQiJcbwB8Qy",
        "outputId": "a84df67c-151c-47e5-f413-7234101e0a36"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 Loaded cv020_9234.txt\n",
            "2 Loaded cv018_21672.txt\n",
            "3 Loaded cv016_4348.txt\n",
            "4 Loaded cv012_29411.txt\n",
            "5 Loaded cv017_23487.txt\n",
            "6 Loaded cv015_29356.txt\n",
            "7 Loaded cv014_15600.txt\n",
            "8 Loaded cv011_13044.txt\n",
            "9 Loaded cv019_16117.txt\n",
            "10 Loaded cv013_10494.txt\n",
            "11 Loaded cv010_29063.txt\n",
            "12 Loaded cv003_12683.txt\n",
            "13 Loaded cv006_17022.txt\n",
            "14 Loaded cv007_4992.txt\n",
            "15 Loaded cv008_29326.txt\n",
            "16 Loaded cv002_17424.txt\n",
            "17 Loaded cv001_19502.txt\n",
            "18 Loaded cv005_29357.txt\n",
            "19 Loaded cv004_12641.txt\n",
            "20 Loaded cv009_29417.txt\n",
            "21 Loaded cv000_29416.txt\n",
            "22 Loaded cv070_13249.txt\n",
            "23 Loaded cv056_14663.txt\n",
            "24 Loaded cv053_23117.txt\n",
            "25 Loaded cv052_29318.txt\n",
            "26 Loaded cv051_10751.txt\n",
            "27 Loaded cv058_8469.txt\n",
            "28 Loaded cv055_8926.txt\n",
            "29 Loaded cv057_7962.txt\n",
            "30 Loaded cv059_28723.txt\n",
            "31 Loaded cv054_4101.txt\n",
            "32 Loaded cv069_11613.txt\n",
            "33 Loaded cv062_24556.txt\n",
            "34 Loaded cv068_14810.txt\n",
            "35 Loaded cv067_21192.txt\n",
            "36 Loaded cv064_25842.txt\n",
            "37 Loaded cv066_11668.txt\n",
            "38 Loaded cv065_16909.txt\n",
            "39 Loaded cv061_9321.txt\n",
            "40 Loaded cv063_28852.txt\n",
            "41 Loaded cv060_11754.txt\n",
            "42 Loaded cv042_11927.txt\n",
            "43 Loaded cv049_21917.txt\n",
            "44 Loaded cv044_18429.txt\n",
            "45 Loaded cv045_25077.txt\n",
            "46 Loaded cv046_10613.txt\n",
            "47 Loaded cv043_16808.txt\n",
            "48 Loaded cv047_18725.txt\n",
            "49 Loaded cv041_22364.txt\n",
            "50 Loaded cv048_18380.txt\n",
            "51 Loaded cv050_12128.txt\n",
            "52 Loaded cv038_9781.txt\n",
            "53 Loaded cv030_22893.txt\n",
            "54 Loaded cv037_19798.txt\n",
            "55 Loaded cv032_23718.txt\n",
            "56 Loaded cv039_5963.txt\n",
            "57 Loaded cv034_29446.txt\n",
            "58 Loaded cv036_18385.txt\n",
            "59 Loaded cv035_3343.txt\n",
            "60 Loaded cv033_25680.txt\n",
            "61 Loaded cv040_8829.txt\n",
            "62 Loaded cv027_26270.txt\n",
            "63 Loaded cv028_26964.txt\n",
            "64 Loaded cv024_7033.txt\n",
            "65 Loaded cv021_17313.txt\n",
            "66 Loaded cv022_14227.txt\n",
            "67 Loaded cv029_19943.txt\n",
            "68 Loaded cv023_13847.txt\n",
            "69 Loaded cv025_29825.txt\n",
            "70 Loaded cv026_29229.txt\n",
            "71 Loaded cv031_19540.txt\n",
            "72 Loaded cv101_10537.txt\n",
            "73 Loaded cv103_11943.txt\n",
            "74 Loaded cv106_18379.txt\n",
            "75 Loaded cv108_17064.txt\n",
            "76 Loaded cv107_25639.txt\n",
            "77 Loaded cv105_19135.txt\n",
            "78 Loaded cv102_8306.txt\n",
            "79 Loaded cv109_22599.txt\n",
            "80 Loaded cv104_19176.txt\n",
            "81 Loaded cv120_3793.txt\n",
            "82 Loaded cv119_9909.txt\n",
            "83 Loaded cv118_28837.txt\n",
            "84 Loaded cv111_12253.txt\n",
            "85 Loaded cv115_26443.txt\n",
            "86 Loaded cv113_24354.txt\n",
            "87 Loaded cv114_19501.txt\n",
            "88 Loaded cv112_12178.txt\n",
            "89 Loaded cv117_25625.txt\n",
            "90 Loaded cv116_28734.txt\n",
            "91 Loaded cv110_27832.txt\n",
            "92 Loaded cv094_27868.txt\n",
            "93 Loaded cv098_17021.txt\n",
            "94 Loaded cv096_12262.txt\n",
            "95 Loaded cv095_28730.txt\n",
            "96 Loaded cv092_27987.txt\n",
            "97 Loaded cv091_7899.txt\n",
            "98 Loaded cv099_11189.txt\n",
            "99 Loaded cv093_15606.txt\n",
            "100 Loaded cv100_12406.txt\n",
            "101 Loaded cv088_25274.txt\n",
            "102 Loaded cv087_2145.txt\n",
            "103 Loaded cv083_25491.txt\n",
            "104 Loaded cv082_11979.txt\n",
            "105 Loaded cv089_12222.txt\n",
            "106 Loaded cv084_15183.txt\n",
            "107 Loaded cv086_19488.txt\n",
            "108 Loaded cv085_15286.txt\n",
            "109 Loaded cv081_18241.txt\n",
            "110 Loaded cv097_26081.txt\n",
            "111 Loaded cv090_0049.txt\n",
            "112 Loaded cv074_7188.txt\n",
            "113 Loaded cv077_23172.txt\n",
            "114 Loaded cv071_12969.txt\n",
            "115 Loaded cv079_12766.txt\n",
            "116 Loaded cv073_23039.txt\n",
            "117 Loaded cv076_26009.txt\n",
            "118 Loaded cv075_6250.txt\n",
            "119 Loaded cv072_5928.txt\n",
            "120 Loaded cv078_16506.txt\n",
            "121 Loaded cv080_14899.txt\n",
            "122 Loaded cv170_29808.txt\n",
            "123 Loaded cv156_11119.txt\n",
            "124 Loaded cv157_29302.txt\n",
            "125 Loaded cv151_17231.txt\n",
            "126 Loaded cv158_10914.txt\n",
            "127 Loaded cv155_7845.txt\n",
            "128 Loaded cv153_11607.txt\n",
            "129 Loaded cv152_9052.txt\n",
            "130 Loaded cv159_29374.txt\n",
            "131 Loaded cv154_9562.txt\n",
            "132 Loaded cv165_2389.txt\n",
            "133 Loaded cv161_12224.txt\n",
            "134 Loaded cv164_23451.txt\n",
            "135 Loaded cv162_10977.txt\n",
            "136 Loaded cv168_7435.txt\n",
            "137 Loaded cv169_24973.txt\n",
            "138 Loaded cv167_18094.txt\n",
            "139 Loaded cv163_10110.txt\n",
            "140 Loaded cv166_11959.txt\n",
            "141 Loaded cv160_10848.txt\n",
            "142 Loaded cv148_18084.txt\n",
            "143 Loaded cv141_17179.txt\n",
            "144 Loaded cv145_12239.txt\n",
            "145 Loaded cv143_21158.txt\n",
            "146 Loaded cv147_22625.txt\n",
            "147 Loaded cv149_17084.txt\n",
            "148 Loaded cv142_23657.txt\n",
            "149 Loaded cv146_19587.txt\n",
            "150 Loaded cv144_5010.txt\n",
            "151 Loaded cv139_14236.txt\n",
            "152 Loaded cv137_17020.txt\n",
            "153 Loaded cv136_12384.txt\n",
            "154 Loaded cv132_5423.txt\n",
            "155 Loaded cv138_13903.txt\n",
            "156 Loaded cv135_12506.txt\n",
            "157 Loaded cv134_23300.txt\n",
            "158 Loaded cv133_18065.txt\n",
            "159 Loaded cv131_11568.txt\n",
            "160 Loaded cv150_14279.txt\n",
            "161 Loaded cv140_7963.txt\n",
            "162 Loaded cv122_7891.txt\n",
            "163 Loaded cv127_16451.txt\n",
            "164 Loaded cv125_9636.txt\n",
            "165 Loaded cv124_3903.txt\n",
            "166 Loaded cv128_29444.txt\n",
            "167 Loaded cv126_28821.txt\n",
            "168 Loaded cv129_18373.txt\n",
            "169 Loaded cv123_12165.txt\n",
            "170 Loaded cv121_18621.txt\n",
            "171 Loaded cv130_18521.txt\n",
            "172 Loaded cv230_7913.txt\n",
            "173 Loaded cv223_28923.txt\n",
            "174 Loaded cv226_26692.txt\n",
            "175 Loaded cv225_29083.txt\n",
            "176 Loaded cv222_18720.txt\n",
            "177 Loaded cv224_18875.txt\n",
            "178 Loaded cv228_5644.txt\n",
            "179 Loaded cv227_25406.txt\n",
            "180 Loaded cv229_15200.txt\n",
            "181 Loaded cv221_27081.txt\n",
            "182 Loaded cv205_9676.txt\n",
            "183 Loaded cv208_9475.txt\n",
            "184 Loaded cv206_15893.txt\n",
            "185 Loaded cv207_29141.txt\n",
            "186 Loaded cv200_29006.txt\n",
            "187 Loaded cv202_11382.txt\n",
            "188 Loaded cv209_28973.txt\n",
            "189 Loaded cv204_8930.txt\n",
            "190 Loaded cv203_19052.txt\n",
            "191 Loaded cv220_28906.txt\n",
            "192 Loaded cv216_20165.txt\n",
            "193 Loaded cv219_19874.txt\n",
            "194 Loaded cv210_9557.txt\n",
            "195 Loaded cv217_28707.txt\n",
            "196 Loaded cv215_23246.txt\n",
            "197 Loaded cv218_25651.txt\n",
            "198 Loaded cv212_10054.txt\n",
            "199 Loaded cv214_13285.txt\n",
            "200 Loaded cv213_20300.txt\n",
            "201 Loaded cv211_9955.txt\n",
            "202 Loaded cv193_5393.txt\n",
            "203 Loaded cv192_16079.txt\n",
            "204 Loaded cv195_16146.txt\n",
            "205 Loaded cv199_9721.txt\n",
            "206 Loaded cv196_28898.txt\n",
            "207 Loaded cv197_29271.txt\n",
            "208 Loaded cv194_12855.txt\n",
            "209 Loaded cv191_29539.txt\n",
            "210 Loaded cv198_19313.txt\n",
            "211 Loaded cv201_7421.txt\n",
            "212 Loaded cv181_16083.txt\n",
            "213 Loaded cv189_24248.txt\n",
            "214 Loaded cv182_7791.txt\n",
            "215 Loaded cv187_14112.txt\n",
            "216 Loaded cv183_19826.txt\n",
            "217 Loaded cv185_28372.txt\n",
            "218 Loaded cv186_2396.txt\n",
            "219 Loaded cv188_20687.txt\n",
            "220 Loaded cv184_26935.txt\n",
            "221 Loaded cv190_27176.txt\n",
            "222 Loaded cv171_15164.txt\n",
            "223 Loaded cv174_9735.txt\n",
            "224 Loaded cv173_4295.txt\n",
            "225 Loaded cv172_12037.txt\n",
            "226 Loaded cv175_7375.txt\n",
            "227 Loaded cv177_10904.txt\n",
            "228 Loaded cv176_14196.txt\n",
            "229 Loaded cv178_14380.txt\n",
            "230 Loaded cv179_9533.txt\n",
            "231 Loaded cv180_17823.txt\n",
            "232 Loaded cv269_23018.txt\n",
            "233 Loaded cv268_20288.txt\n",
            "234 Loaded cv264_14108.txt\n",
            "235 Loaded cv263_20693.txt\n",
            "236 Loaded cv262_13812.txt\n",
            "237 Loaded cv261_11855.txt\n",
            "238 Loaded cv267_16618.txt\n",
            "239 Loaded cv265_11625.txt\n",
            "240 Loaded cv266_26644.txt\n",
            "241 Loaded cv280_8651.txt\n",
            "242 Loaded cv279_19452.txt\n",
            "243 Loaded cv274_26379.txt\n",
            "244 Loaded cv272_20313.txt\n",
            "245 Loaded cv278_14533.txt\n",
            "246 Loaded cv275_28725.txt\n",
            "247 Loaded cv273_28961.txt\n",
            "248 Loaded cv277_20467.txt\n",
            "249 Loaded cv276_17126.txt\n",
            "250 Loaded cv271_15364.txt\n",
            "251 Loaded cv270_5873.txt\n",
            "252 Loaded cv258_5627.txt\n",
            "253 Loaded cv251_23901.txt\n",
            "254 Loaded cv256_16529.txt\n",
            "255 Loaded cv255_15267.txt\n",
            "256 Loaded cv253_10190.txt\n",
            "257 Loaded cv252_24974.txt\n",
            "258 Loaded cv254_5870.txt\n",
            "259 Loaded cv257_11856.txt\n",
            "260 Loaded cv260_15652.txt\n",
            "261 Loaded cv249_12674.txt\n",
            "262 Loaded cv246_28668.txt\n",
            "263 Loaded cv244_22935.txt\n",
            "264 Loaded cv247_14668.txt\n",
            "265 Loaded cv245_8938.txt\n",
            "266 Loaded cv248_15672.txt\n",
            "267 Loaded cv241_24602.txt\n",
            "268 Loaded cv243_22164.txt\n",
            "269 Loaded cv242_11354.txt\n",
            "270 Loaded cv259_11827.txt\n",
            "271 Loaded cv250_26462.txt\n",
            "272 Loaded cv232_16768.txt\n",
            "273 Loaded cv238_14285.txt\n",
            "274 Loaded cv234_22123.txt\n",
            "275 Loaded cv236_12427.txt\n",
            "276 Loaded cv237_20635.txt\n",
            "277 Loaded cv231_11028.txt\n",
            "278 Loaded cv233_17614.txt\n",
            "279 Loaded cv235_10704.txt\n",
            "280 Loaded cv239_29828.txt\n",
            "281 Loaded cv240_15948.txt\n",
            "282 Loaded cv339_22452.txt\n",
            "283 Loaded cv331_8656.txt\n",
            "284 Loaded cv338_9183.txt\n",
            "285 Loaded cv333_9443.txt\n",
            "286 Loaded cv334_0074.txt\n",
            "287 Loaded cv337_29061.txt\n",
            "288 Loaded cv332_17997.txt\n",
            "289 Loaded cv336_10363.txt\n",
            "290 Loaded cv335_16299.txt\n",
            "291 Loaded cv330_29675.txt\n",
            "292 Loaded cv311_17708.txt\n",
            "293 Loaded cv316_5972.txt\n",
            "294 Loaded cv318_11146.txt\n",
            "295 Loaded cv317_25111.txt\n",
            "296 Loaded cv315_12638.txt\n",
            "297 Loaded cv314_16095.txt\n",
            "298 Loaded cv319_16459.txt\n",
            "299 Loaded cv312_29308.txt\n",
            "300 Loaded cv313_19337.txt\n",
            "301 Loaded cv326_14777.txt\n",
            "302 Loaded cv325_18330.txt\n",
            "303 Loaded cv323_29633.txt\n",
            "304 Loaded cv327_21743.txt\n",
            "305 Loaded cv322_21820.txt\n",
            "306 Loaded cv321_14191.txt\n",
            "307 Loaded cv329_29293.txt\n",
            "308 Loaded cv324_7502.txt\n",
            "309 Loaded cv328_10908.txt\n",
            "310 Loaded cv320_9693.txt\n",
            "311 Loaded cv309_23737.txt\n",
            "312 Loaded cv303_27366.txt\n",
            "313 Loaded cv307_26382.txt\n",
            "314 Loaded cv304_28489.txt\n",
            "315 Loaded cv302_26481.txt\n",
            "316 Loaded cv305_9937.txt\n",
            "317 Loaded cv308_5079.txt\n",
            "318 Loaded cv301_13010.txt\n",
            "319 Loaded cv306_10859.txt\n",
            "320 Loaded cv295_17060.txt\n",
            "321 Loaded cv292_7804.txt\n",
            "322 Loaded cv299_17950.txt\n",
            "323 Loaded cv291_26844.txt\n",
            "324 Loaded cv297_10104.txt\n",
            "325 Loaded cv293_29731.txt\n",
            "326 Loaded cv294_12695.txt\n",
            "327 Loaded cv298_24487.txt\n",
            "328 Loaded cv296_13146.txt\n",
            "329 Loaded cv310_14568.txt\n",
            "330 Loaded cv300_23302.txt\n",
            "331 Loaded cv284_20530.txt\n",
            "332 Loaded cv285_18186.txt\n",
            "333 Loaded cv283_11963.txt\n",
            "334 Loaded cv287_17410.txt\n",
            "335 Loaded cv288_20212.txt\n",
            "336 Loaded cv281_24711.txt\n",
            "337 Loaded cv289_6239.txt\n",
            "338 Loaded cv282_6833.txt\n",
            "339 Loaded cv286_26156.txt\n",
            "340 Loaded cv290_11981.txt\n",
            "341 Loaded cv390_12187.txt\n",
            "342 Loaded cv388_12810.txt\n",
            "343 Loaded cv382_8393.txt\n",
            "344 Loaded cv386_10229.txt\n",
            "345 Loaded cv385_29621.txt\n",
            "346 Loaded cv381_21673.txt\n",
            "347 Loaded cv384_18536.txt\n",
            "348 Loaded cv383_14662.txt\n",
            "349 Loaded cv389_9611.txt\n",
            "350 Loaded cv387_12391.txt\n",
            "351 Loaded cv363_29273.txt\n",
            "352 Loaded cv366_10709.txt\n",
            "353 Loaded cv368_11090.txt\n",
            "354 Loaded cv365_12442.txt\n",
            "355 Loaded cv362_16985.txt\n",
            "356 Loaded cv361_28738.txt\n",
            "357 Loaded cv369_14245.txt\n",
            "358 Loaded cv364_14254.txt\n",
            "359 Loaded cv367_24065.txt\n",
            "360 Loaded cv380_8164.txt\n",
            "361 Loaded cv374_26455.txt\n",
            "362 Loaded cv377_8440.txt\n",
            "363 Loaded cv373_21872.txt\n",
            "364 Loaded cv376_20883.txt\n",
            "365 Loaded cv372_6654.txt\n",
            "366 Loaded cv379_23167.txt\n",
            "367 Loaded cv375_9932.txt\n",
            "368 Loaded cv371_8197.txt\n",
            "369 Loaded cv378_21982.txt\n",
            "370 Loaded cv353_19197.txt\n",
            "371 Loaded cv351_17029.txt\n",
            "372 Loaded cv357_14710.txt\n",
            "373 Loaded cv358_11557.txt\n",
            "374 Loaded cv356_26170.txt\n",
            "375 Loaded cv355_18174.txt\n",
            "376 Loaded cv354_8573.txt\n",
            "377 Loaded cv352_5414.txt\n",
            "378 Loaded cv359_6751.txt\n",
            "379 Loaded cv370_5338.txt\n",
            "380 Loaded cv360_8927.txt\n",
            "381 Loaded cv342_20917.txt\n",
            "382 Loaded cv344_5376.txt\n",
            "383 Loaded cv347_14722.txt\n",
            "384 Loaded cv346_19198.txt\n",
            "385 Loaded cv349_15032.txt\n",
            "386 Loaded cv348_19207.txt\n",
            "387 Loaded cv343_10906.txt\n",
            "388 Loaded cv341_25667.txt\n",
            "389 Loaded cv345_9966.txt\n",
            "390 Loaded cv350_22139.txt\n",
            "391 Loaded cv340_14776.txt\n",
            "392 Loaded cv428_12202.txt\n",
            "393 Loaded cv423_12089.txt\n",
            "394 Loaded cv425_8603.txt\n",
            "395 Loaded cv427_11693.txt\n",
            "396 Loaded cv426_10976.txt\n",
            "397 Loaded cv424_9268.txt\n",
            "398 Loaded cv422_9632.txt\n",
            "399 Loaded cv421_9752.txt\n",
            "400 Loaded cv440_16891.txt\n",
            "401 Loaded cv432_15873.txt\n",
            "402 Loaded cv437_24070.txt\n",
            "403 Loaded cv435_24355.txt\n",
            "404 Loaded cv439_17633.txt\n",
            "405 Loaded cv431_7538.txt\n",
            "406 Loaded cv438_8500.txt\n",
            "407 Loaded cv434_5641.txt\n",
            "408 Loaded cv436_20564.txt\n",
            "409 Loaded cv433_10443.txt\n",
            "410 Loaded cv430_18662.txt\n",
            "411 Loaded cv419_14799.txt\n",
            "412 Loaded cv414_11161.txt\n",
            "413 Loaded cv412_25254.txt\n",
            "414 Loaded cv416_12048.txt\n",
            "415 Loaded cv413_7893.txt\n",
            "416 Loaded cv418_16562.txt\n",
            "417 Loaded cv411_16799.txt\n",
            "418 Loaded cv415_23674.txt\n",
            "419 Loaded cv417_14653.txt\n",
            "420 Loaded cv429_7937.txt\n",
            "421 Loaded cv420_28631.txt\n",
            "422 Loaded cv402_16097.txt\n",
            "423 Loaded cv407_23928.txt\n",
            "424 Loaded cv403_6721.txt\n",
            "425 Loaded cv401_13758.txt\n",
            "426 Loaded cv408_5367.txt\n",
            "427 Loaded cv404_21805.txt\n",
            "428 Loaded cv409_29625.txt\n",
            "429 Loaded cv406_22199.txt\n",
            "430 Loaded cv405_21868.txt\n",
            "431 Loaded cv410_25624.txt\n",
            "432 Loaded cv396_19127.txt\n",
            "433 Loaded cv395_11761.txt\n",
            "434 Loaded cv399_28593.txt\n",
            "435 Loaded cv394_5311.txt\n",
            "436 Loaded cv391_11615.txt\n",
            "437 Loaded cv398_17047.txt\n",
            "438 Loaded cv393_29234.txt\n",
            "439 Loaded cv392_12238.txt\n",
            "440 Loaded cv397_28890.txt\n",
            "441 Loaded cv400_20631.txt\n",
            "442 Loaded cv493_14135.txt\n",
            "443 Loaded cv496_11185.txt\n",
            "444 Loaded cv492_19370.txt\n",
            "445 Loaded cv494_18689.txt\n",
            "446 Loaded cv499_11407.txt\n",
            "447 Loaded cv495_16121.txt\n",
            "448 Loaded cv490_18986.txt\n",
            "449 Loaded cv498_9288.txt\n",
            "450 Loaded cv497_27086.txt\n",
            "451 Loaded cv474_10682.txt\n",
            "452 Loaded cv476_18402.txt\n",
            "453 Loaded cv478_15921.txt\n",
            "454 Loaded cv473_7869.txt\n",
            "455 Loaded cv477_23530.txt\n",
            "456 Loaded cv479_5450.txt\n",
            "457 Loaded cv475_22978.txt\n",
            "458 Loaded cv471_18405.txt\n",
            "459 Loaded cv472_29140.txt\n",
            "460 Loaded cv491_12992.txt\n",
            "461 Loaded cv487_11058.txt\n",
            "462 Loaded cv486_9788.txt\n",
            "463 Loaded cv482_11233.txt\n",
            "464 Loaded cv485_26879.txt\n",
            "465 Loaded cv488_21453.txt\n",
            "466 Loaded cv481_7930.txt\n",
            "467 Loaded cv489_19046.txt\n",
            "468 Loaded cv484_26169.txt\n",
            "469 Loaded cv483_18103.txt\n",
            "470 Loaded cv480_21195.txt\n",
            "471 Loaded cv467_26610.txt\n",
            "472 Loaded cv461_21124.txt\n",
            "473 Loaded cv462_20788.txt\n",
            "474 Loaded cv466_20092.txt\n",
            "475 Loaded cv463_10846.txt\n",
            "476 Loaded cv468_16844.txt\n",
            "477 Loaded cv469_21998.txt\n",
            "478 Loaded cv465_23401.txt\n",
            "479 Loaded cv464_17076.txt\n",
            "480 Loaded cv470_17444.txt\n",
            "481 Loaded cv458_9000.txt\n",
            "482 Loaded cv451_11502.txt\n",
            "483 Loaded cv454_21961.txt\n",
            "484 Loaded cv457_19546.txt\n",
            "485 Loaded cv459_21834.txt\n",
            "486 Loaded cv456_20370.txt\n",
            "487 Loaded cv452_5179.txt\n",
            "488 Loaded cv453_10911.txt\n",
            "489 Loaded cv455_28866.txt\n",
            "490 Loaded cv448_16409.txt\n",
            "491 Loaded cv444_9975.txt\n",
            "492 Loaded cv446_12209.txt\n",
            "493 Loaded cv441_15276.txt\n",
            "494 Loaded cv442_15499.txt\n",
            "495 Loaded cv443_22367.txt\n",
            "496 Loaded cv445_26683.txt\n",
            "497 Loaded cv449_9126.txt\n",
            "498 Loaded cv447_27334.txt\n",
            "499 Loaded cv460_11723.txt\n",
            "500 Loaded cv450_8319.txt\n",
            "501 Loaded cv539_21865.txt\n",
            "502 Loaded cv538_28485.txt\n",
            "503 Loaded cv531_26838.txt\n",
            "504 Loaded cv534_15683.txt\n",
            "505 Loaded cv535_21183.txt\n",
            "506 Loaded cv532_6495.txt\n",
            "507 Loaded cv537_13516.txt\n",
            "508 Loaded cv533_9843.txt\n",
            "509 Loaded cv536_27221.txt\n",
            "510 Loaded cv542_20359.txt\n",
            "511 Loaded cv548_18944.txt\n",
            "512 Loaded cv546_12723.txt\n",
            "513 Loaded cv541_28683.txt\n",
            "514 Loaded cv549_22771.txt\n",
            "515 Loaded cv547_18043.txt\n",
            "516 Loaded cv544_5301.txt\n",
            "517 Loaded cv543_5107.txt\n",
            "518 Loaded cv545_12848.txt\n",
            "519 Loaded cv540_3092.txt\n",
            "520 Loaded cv528_11669.txt\n",
            "521 Loaded cv524_24885.txt\n",
            "522 Loaded cv526_12868.txt\n",
            "523 Loaded cv522_5418.txt\n",
            "524 Loaded cv527_10338.txt\n",
            "525 Loaded cv529_10972.txt\n",
            "526 Loaded cv525_17930.txt\n",
            "527 Loaded cv523_18285.txt\n",
            "528 Loaded cv521_1730.txt\n",
            "529 Loaded cv516_12117.txt\n",
            "530 Loaded cv514_12173.txt\n",
            "531 Loaded cv512_17618.txt\n",
            "532 Loaded cv519_16239.txt\n",
            "533 Loaded cv517_20616.txt\n",
            "534 Loaded cv513_7236.txt\n",
            "535 Loaded cv511_10360.txt\n",
            "536 Loaded cv518_14798.txt\n",
            "537 Loaded cv515_18484.txt\n",
            "538 Loaded cv530_17949.txt\n",
            "539 Loaded cv509_17354.txt\n",
            "540 Loaded cv501_12675.txt\n",
            "541 Loaded cv504_29120.txt\n",
            "542 Loaded cv503_11196.txt\n",
            "543 Loaded cv507_9509.txt\n",
            "544 Loaded cv508_17742.txt\n",
            "545 Loaded cv505_12926.txt\n",
            "546 Loaded cv506_17521.txt\n",
            "547 Loaded cv502_10970.txt\n",
            "548 Loaded cv520_13297.txt\n",
            "549 Loaded cv510_24758.txt\n",
            "550 Loaded cv500_10722.txt\n",
            "551 Loaded cv590_20712.txt\n",
            "552 Loaded cv585_23576.txt\n",
            "553 Loaded cv581_20790.txt\n",
            "554 Loaded cv583_29465.txt\n",
            "555 Loaded cv589_12853.txt\n",
            "556 Loaded cv588_14467.txt\n",
            "557 Loaded cv586_8048.txt\n",
            "558 Loaded cv587_20532.txt\n",
            "559 Loaded cv582_6678.txt\n",
            "560 Loaded cv584_29549.txt\n",
            "561 Loaded cv578_16825.txt\n",
            "562 Loaded cv571_29292.txt\n",
            "563 Loaded cv574_23191.txt\n",
            "564 Loaded cv575_22598.txt\n",
            "565 Loaded cv577_28220.txt\n",
            "566 Loaded cv572_20053.txt\n",
            "567 Loaded cv576_15688.txt\n",
            "568 Loaded cv573_29384.txt\n",
            "569 Loaded cv580_15681.txt\n",
            "570 Loaded cv564_12011.txt\n",
            "571 Loaded cv566_8967.txt\n",
            "572 Loaded cv561_9484.txt\n",
            "573 Loaded cv568_17065.txt\n",
            "574 Loaded cv565_29403.txt\n",
            "575 Loaded cv562_10847.txt\n",
            "576 Loaded cv569_26750.txt\n",
            "577 Loaded cv563_18610.txt\n",
            "578 Loaded cv567_29420.txt\n",
            "579 Loaded cv579_12542.txt\n",
            "580 Loaded cv570_28960.txt\n",
            "581 Loaded cv557_12237.txt\n",
            "582 Loaded cv554_14678.txt\n",
            "583 Loaded cv556_16563.txt\n",
            "584 Loaded cv553_26965.txt\n",
            "585 Loaded cv555_25047.txt\n",
            "586 Loaded cv559_0057.txt\n",
            "587 Loaded cv558_29376.txt\n",
            "588 Loaded cv550_23226.txt\n",
            "589 Loaded cv552_0150.txt\n",
            "590 Loaded cv560_18608.txt\n",
            "591 Loaded cv551_11214.txt\n",
            "592 Loaded cv641_13412.txt\n",
            "593 Loaded cv647_15275.txt\n",
            "594 Loaded cv644_18551.txt\n",
            "595 Loaded cv646_16817.txt\n",
            "596 Loaded cv645_17078.txt\n",
            "597 Loaded cv642_29788.txt\n",
            "598 Loaded cv643_29282.txt\n",
            "599 Loaded cv649_13947.txt\n",
            "600 Loaded cv648_17277.txt\n",
            "601 Loaded cv629_16604.txt\n",
            "602 Loaded cv625_13518.txt\n",
            "603 Loaded cv626_7907.txt\n",
            "604 Loaded cv621_15984.txt\n",
            "605 Loaded cv623_16988.txt\n",
            "606 Loaded cv628_20758.txt\n",
            "607 Loaded cv622_8583.txt\n",
            "608 Loaded cv627_12603.txt\n",
            "609 Loaded cv624_11601.txt\n",
            "610 Loaded cv640_5380.txt\n",
            "611 Loaded cv634_11989.txt\n",
            "612 Loaded cv632_9704.txt\n",
            "613 Loaded cv636_16954.txt\n",
            "614 Loaded cv635_0984.txt\n",
            "615 Loaded cv638_29394.txt\n",
            "616 Loaded cv637_13682.txt\n",
            "617 Loaded cv639_10797.txt\n",
            "618 Loaded cv631_4782.txt\n",
            "619 Loaded cv633_29730.txt\n",
            "620 Loaded cv630_10152.txt\n",
            "621 Loaded cv612_5396.txt\n",
            "622 Loaded cv615_15734.txt\n",
            "623 Loaded cv614_11320.txt\n",
            "624 Loaded cv616_29187.txt\n",
            "625 Loaded cv618_9469.txt\n",
            "626 Loaded cv619_13677.txt\n",
            "627 Loaded cv617_9561.txt\n",
            "628 Loaded cv611_2253.txt\n",
            "629 Loaded cv613_23104.txt\n",
            "630 Loaded cv620_2556.txt\n",
            "631 Loaded cv603_18885.txt\n",
            "632 Loaded cv607_8235.txt\n",
            "633 Loaded cv608_24647.txt\n",
            "634 Loaded cv606_17672.txt\n",
            "635 Loaded cv605_12730.txt\n",
            "636 Loaded cv609_25038.txt\n",
            "637 Loaded cv600_25043.txt\n",
            "638 Loaded cv602_8830.txt\n",
            "639 Loaded cv604_23339.txt\n",
            "640 Loaded cv610_24153.txt\n",
            "641 Loaded cv598_18184.txt\n",
            "642 Loaded cv597_26744.txt\n",
            "643 Loaded cv596_4367.txt\n",
            "644 Loaded cv593_11931.txt\n",
            "645 Loaded cv592_23391.txt\n",
            "646 Loaded cv594_11945.txt\n",
            "647 Loaded cv591_24887.txt\n",
            "648 Loaded cv595_26420.txt\n",
            "649 Loaded cv601_24759.txt\n",
            "650 Loaded cv599_22197.txt\n",
            "651 Loaded cv683_13047.txt\n",
            "652 Loaded cv688_7884.txt\n",
            "653 Loaded cv681_9744.txt\n",
            "654 Loaded cv685_5710.txt\n",
            "655 Loaded cv687_22207.txt\n",
            "656 Loaded cv689_13701.txt\n",
            "657 Loaded cv684_12727.txt\n",
            "658 Loaded cv682_17947.txt\n",
            "659 Loaded cv686_15553.txt\n",
            "660 Loaded cv700_23163.txt\n",
            "661 Loaded cv694_4526.txt\n",
            "662 Loaded cv699_7773.txt\n",
            "663 Loaded cv696_29619.txt\n",
            "664 Loaded cv691_5090.txt\n",
            "665 Loaded cv692_17026.txt\n",
            "666 Loaded cv698_16930.txt\n",
            "667 Loaded cv693_19147.txt\n",
            "668 Loaded cv695_22268.txt\n",
            "669 Loaded cv697_12106.txt\n",
            "670 Loaded cv690_5425.txt\n",
            "671 Loaded cv675_22871.txt\n",
            "672 Loaded cv673_25874.txt\n",
            "673 Loaded cv674_11593.txt\n",
            "674 Loaded cv678_14887.txt\n",
            "675 Loaded cv671_5164.txt\n",
            "676 Loaded cv672_27988.txt\n",
            "677 Loaded cv679_28221.txt\n",
            "678 Loaded cv677_18938.txt\n",
            "679 Loaded cv676_22202.txt\n",
            "680 Loaded cv680_10533.txt\n",
            "681 Loaded cv666_20301.txt\n",
            "682 Loaded cv668_18848.txt\n",
            "683 Loaded cv669_24318.txt\n",
            "684 Loaded cv667_19672.txt\n",
            "685 Loaded cv665_29386.txt\n",
            "686 Loaded cv663_14484.txt\n",
            "687 Loaded cv661_25780.txt\n",
            "688 Loaded cv662_14791.txt\n",
            "689 Loaded cv664_4264.txt\n",
            "690 Loaded cv659_21483.txt\n",
            "691 Loaded cv657_25835.txt\n",
            "692 Loaded cv656_25395.txt\n",
            "693 Loaded cv652_15653.txt\n",
            "694 Loaded cv658_11186.txt\n",
            "695 Loaded cv653_2107.txt\n",
            "696 Loaded cv655_12055.txt\n",
            "697 Loaded cv651_11120.txt\n",
            "698 Loaded cv654_19345.txt\n",
            "699 Loaded cv670_2666.txt\n",
            "700 Loaded cv660_23140.txt\n",
            "701 Loaded cv650_15974.txt\n",
            "702 Loaded cv750_10606.txt\n",
            "703 Loaded cv734_22821.txt\n",
            "704 Loaded cv738_10287.txt\n",
            "705 Loaded cv737_28733.txt\n",
            "706 Loaded cv733_9891.txt\n",
            "707 Loaded cv735_20218.txt\n",
            "708 Loaded cv736_24947.txt\n",
            "709 Loaded cv732_13092.txt\n",
            "710 Loaded cv731_3968.txt\n",
            "711 Loaded cv739_12179.txt\n",
            "712 Loaded cv748_14044.txt\n",
            "713 Loaded cv749_18960.txt\n",
            "714 Loaded cv742_8279.txt\n",
            "715 Loaded cv743_17023.txt\n",
            "716 Loaded cv747_18189.txt\n",
            "717 Loaded cv744_10091.txt\n",
            "718 Loaded cv741_12765.txt\n",
            "719 Loaded cv746_10471.txt\n",
            "720 Loaded cv745_14009.txt\n",
            "721 Loaded cv728_17931.txt\n",
            "722 Loaded cv721_28993.txt\n",
            "723 Loaded cv726_4365.txt\n",
            "724 Loaded cv729_10475.txt\n",
            "725 Loaded cv727_5006.txt\n",
            "726 Loaded cv722_7571.txt\n",
            "727 Loaded cv723_9002.txt\n",
            "728 Loaded cv725_10266.txt\n",
            "729 Loaded cv724_15265.txt\n",
            "730 Loaded cv740_13643.txt\n",
            "731 Loaded cv730_10729.txt\n",
            "732 Loaded cv715_19246.txt\n",
            "733 Loaded cv716_11153.txt\n",
            "734 Loaded cv713_29002.txt\n",
            "735 Loaded cv717_17472.txt\n",
            "736 Loaded cv711_12687.txt\n",
            "737 Loaded cv712_24217.txt\n",
            "738 Loaded cv718_12227.txt\n",
            "739 Loaded cv714_19704.txt\n",
            "740 Loaded cv719_5581.txt\n",
            "741 Loaded cv720_5383.txt\n",
            "742 Loaded cv702_12371.txt\n",
            "743 Loaded cv707_11421.txt\n",
            "744 Loaded cv701_15880.txt\n",
            "745 Loaded cv706_25883.txt\n",
            "746 Loaded cv704_17622.txt\n",
            "747 Loaded cv703_17948.txt\n",
            "748 Loaded cv708_28539.txt\n",
            "749 Loaded cv709_11173.txt\n",
            "750 Loaded cv705_11973.txt\n",
            "751 Loaded cv710_23745.txt\n",
            "752 Loaded cv800_13494.txt\n",
            "753 Loaded cv789_12991.txt\n",
            "754 Loaded cv784_16077.txt\n",
            "755 Loaded cv787_15277.txt\n",
            "756 Loaded cv781_5358.txt\n",
            "757 Loaded cv785_23748.txt\n",
            "758 Loaded cv786_23608.txt\n",
            "759 Loaded cv783_14724.txt\n",
            "760 Loaded cv782_21078.txt\n",
            "761 Loaded cv788_26409.txt\n",
            "762 Loaded cv775_17966.txt\n",
            "763 Loaded cv774_15488.txt\n",
            "764 Loaded cv771_28466.txt\n",
            "765 Loaded cv772_12971.txt\n",
            "766 Loaded cv778_18629.txt\n",
            "767 Loaded cv779_18989.txt\n",
            "768 Loaded cv776_21934.txt\n",
            "769 Loaded cv777_10247.txt\n",
            "770 Loaded cv773_20264.txt\n",
            "771 Loaded cv799_19812.txt\n",
            "772 Loaded cv797_7245.txt\n",
            "773 Loaded cv795_10291.txt\n",
            "774 Loaded cv791_17995.txt\n",
            "775 Loaded cv798_24779.txt\n",
            "776 Loaded cv796_17243.txt\n",
            "777 Loaded cv793_15235.txt\n",
            "778 Loaded cv792_3257.txt\n",
            "779 Loaded cv794_17353.txt\n",
            "780 Loaded cv790_16202.txt\n",
            "781 Loaded cv769_8565.txt\n",
            "782 Loaded cv761_13769.txt\n",
            "783 Loaded cv764_12701.txt\n",
            "784 Loaded cv765_20429.txt\n",
            "785 Loaded cv762_15604.txt\n",
            "786 Loaded cv766_7983.txt\n",
            "787 Loaded cv768_12709.txt\n",
            "788 Loaded cv763_16486.txt\n",
            "789 Loaded cv767_15673.txt\n",
            "790 Loaded cv780_8467.txt\n",
            "791 Loaded cv770_11061.txt\n",
            "792 Loaded cv759_15091.txt\n",
            "793 Loaded cv751_17208.txt\n",
            "794 Loaded cv755_24881.txt\n",
            "795 Loaded cv754_7709.txt\n",
            "796 Loaded cv753_11812.txt\n",
            "797 Loaded cv757_10668.txt\n",
            "798 Loaded cv758_9740.txt\n",
            "799 Loaded cv756_23676.txt\n",
            "800 Loaded cv752_25330.txt\n",
            "801 Loaded cv760_8977.txt\n",
            "802 Loaded cv852_27512.txt\n",
            "803 Loaded cv854_18955.txt\n",
            "804 Loaded cv856_28882.txt\n",
            "805 Loaded cv858_20266.txt\n",
            "806 Loaded cv855_22134.txt\n",
            "807 Loaded cv851_21895.txt\n",
            "808 Loaded cv853_29119.txt\n",
            "809 Loaded cv859_15689.txt\n",
            "810 Loaded cv857_17527.txt\n",
            "811 Loaded cv850_18185.txt\n",
            "812 Loaded cv831_16325.txt\n",
            "813 Loaded cv833_11961.txt\n",
            "814 Loaded cv834_23192.txt\n",
            "815 Loaded cv838_25886.txt\n",
            "816 Loaded cv832_24713.txt\n",
            "817 Loaded cv837_27232.txt\n",
            "818 Loaded cv835_20531.txt\n",
            "819 Loaded cv836_14311.txt\n",
            "820 Loaded cv839_22807.txt\n",
            "821 Loaded cv849_17215.txt\n",
            "822 Loaded cv847_20855.txt\n",
            "823 Loaded cv846_29359.txt\n",
            "824 Loaded cv848_10061.txt\n",
            "825 Loaded cv843_17054.txt\n",
            "826 Loaded cv841_3367.txt\n",
            "827 Loaded cv844_13890.txt\n",
            "828 Loaded cv842_5702.txt\n",
            "829 Loaded cv845_15886.txt\n",
            "830 Loaded cv822_21545.txt\n",
            "831 Loaded cv823_17055.txt\n",
            "832 Loaded cv825_5168.txt\n",
            "833 Loaded cv827_19479.txt\n",
            "834 Loaded cv826_12761.txt\n",
            "835 Loaded cv820_24157.txt\n",
            "836 Loaded cv824_9335.txt\n",
            "837 Loaded cv828_21392.txt\n",
            "838 Loaded cv829_21725.txt\n",
            "839 Loaded cv840_18033.txt\n",
            "840 Loaded cv830_5778.txt\n",
            "841 Loaded cv819_9567.txt\n",
            "842 Loaded cv814_20316.txt\n",
            "843 Loaded cv813_6649.txt\n",
            "844 Loaded cv818_10698.txt\n",
            "845 Loaded cv810_13660.txt\n",
            "846 Loaded cv816_15257.txt\n",
            "847 Loaded cv815_23466.txt\n",
            "848 Loaded cv812_19051.txt\n",
            "849 Loaded cv817_3675.txt\n",
            "850 Loaded cv821_29283.txt\n",
            "851 Loaded cv801_26335.txt\n",
            "852 Loaded cv807_23024.txt\n",
            "853 Loaded cv804_11763.txt\n",
            "854 Loaded cv802_28381.txt\n",
            "855 Loaded cv809_5012.txt\n",
            "856 Loaded cv805_21128.txt\n",
            "857 Loaded cv803_8584.txt\n",
            "858 Loaded cv808_13773.txt\n",
            "859 Loaded cv806_9405.txt\n",
            "860 Loaded cv811_22646.txt\n",
            "861 Loaded cv909_9973.txt\n",
            "862 Loaded cv908_17779.txt\n",
            "863 Loaded cv903_18981.txt\n",
            "864 Loaded cv902_13217.txt\n",
            "865 Loaded cv904_25663.txt\n",
            "866 Loaded cv901_11934.txt\n",
            "867 Loaded cv907_3193.txt\n",
            "868 Loaded cv905_28965.txt\n",
            "869 Loaded cv906_12332.txt\n",
            "870 Loaded cv900_10800.txt\n",
            "871 Loaded cv889_22670.txt\n",
            "872 Loaded cv886_19210.txt\n",
            "873 Loaded cv882_10042.txt\n",
            "874 Loaded cv888_25678.txt\n",
            "875 Loaded cv881_14767.txt\n",
            "876 Loaded cv884_15230.txt\n",
            "877 Loaded cv883_27621.txt\n",
            "878 Loaded cv887_5306.txt\n",
            "879 Loaded cv885_13390.txt\n",
            "880 Loaded cv899_17812.txt\n",
            "881 Loaded cv895_22200.txt\n",
            "882 Loaded cv897_11703.txt\n",
            "883 Loaded cv898_1576.txt\n",
            "884 Loaded cv894_22140.txt\n",
            "885 Loaded cv892_18788.txt\n",
            "886 Loaded cv891_6035.txt\n",
            "887 Loaded cv893_26731.txt\n",
            "888 Loaded cv896_17819.txt\n",
            "889 Loaded cv890_3515.txt\n",
            "890 Loaded cv877_29132.txt\n",
            "891 Loaded cv871_25971.txt\n",
            "892 Loaded cv873_19937.txt\n",
            "893 Loaded cv878_17204.txt\n",
            "894 Loaded cv875_5622.txt\n",
            "895 Loaded cv879_16585.txt\n",
            "896 Loaded cv874_12182.txt\n",
            "897 Loaded cv872_13710.txt\n",
            "898 Loaded cv876_9633.txt\n",
            "899 Loaded cv880_29629.txt\n",
            "900 Loaded cv861_12809.txt\n",
            "901 Loaded cv863_7912.txt\n",
            "902 Loaded cv866_29447.txt\n",
            "903 Loaded cv869_24782.txt\n",
            "904 Loaded cv865_28796.txt\n",
            "905 Loaded cv864_3087.txt\n",
            "906 Loaded cv868_12799.txt\n",
            "907 Loaded cv862_15924.txt\n",
            "908 Loaded cv867_18362.txt\n",
            "909 Loaded cv870_18090.txt\n",
            "910 Loaded cv860_15520.txt\n",
            "911 Loaded cv960_28877.txt\n",
            "912 Loaded cv952_26375.txt\n",
            "913 Loaded cv956_12547.txt\n",
            "914 Loaded cv957_9059.txt\n",
            "915 Loaded cv951_11816.txt\n",
            "916 Loaded cv959_16218.txt\n",
            "917 Loaded cv955_26154.txt\n",
            "918 Loaded cv953_7078.txt\n",
            "919 Loaded cv958_13020.txt\n",
            "920 Loaded cv954_19932.txt\n",
            "921 Loaded cv950_13478.txt\n",
            "922 Loaded cv939_11247.txt\n",
            "923 Loaded cv935_24977.txt\n",
            "924 Loaded cv930_14949.txt\n",
            "925 Loaded cv934_20426.txt\n",
            "926 Loaded cv938_10706.txt\n",
            "927 Loaded cv932_14854.txt\n",
            "928 Loaded cv936_17473.txt\n",
            "929 Loaded cv937_9816.txt\n",
            "930 Loaded cv933_24953.txt\n",
            "931 Loaded cv943_23547.txt\n",
            "932 Loaded cv946_20084.txt\n",
            "933 Loaded cv944_15042.txt\n",
            "934 Loaded cv941_10718.txt\n",
            "935 Loaded cv948_25870.txt\n",
            "936 Loaded cv949_21565.txt\n",
            "937 Loaded cv947_11316.txt\n",
            "938 Loaded cv945_13012.txt\n",
            "939 Loaded cv942_18509.txt\n",
            "940 Loaded cv940_18935.txt\n",
            "941 Loaded cv929_1841.txt\n",
            "942 Loaded cv926_18471.txt\n",
            "943 Loaded cv928_9478.txt\n",
            "944 Loaded cv922_10185.txt\n",
            "945 Loaded cv924_29397.txt\n",
            "946 Loaded cv923_11951.txt\n",
            "947 Loaded cv921_13988.txt\n",
            "948 Loaded cv925_9459.txt\n",
            "949 Loaded cv927_11471.txt\n",
            "950 Loaded cv931_18783.txt\n",
            "951 Loaded cv919_18155.txt\n",
            "952 Loaded cv917_29484.txt\n",
            "953 Loaded cv911_21695.txt\n",
            "954 Loaded cv918_27080.txt\n",
            "955 Loaded cv912_5562.txt\n",
            "956 Loaded cv914_2856.txt\n",
            "957 Loaded cv916_17034.txt\n",
            "958 Loaded cv915_9342.txt\n",
            "959 Loaded cv913_29127.txt\n",
            "960 Loaded cv920_29423.txt\n",
            "961 Loaded cv910_21930.txt\n",
            "962 Loaded cv998_15691.txt\n",
            "963 Loaded cv996_12447.txt\n",
            "964 Loaded cv992_12806.txt\n",
            "965 Loaded cv993_29565.txt\n",
            "966 Loaded cv997_5152.txt\n",
            "967 Loaded cv990_12443.txt\n",
            "968 Loaded cv995_23113.txt\n",
            "969 Loaded cv994_13229.txt\n",
            "970 Loaded cv989_17297.txt\n",
            "971 Loaded cv981_16679.txt\n",
            "972 Loaded cv988_20168.txt\n",
            "973 Loaded cv982_22209.txt\n",
            "974 Loaded cv984_14006.txt\n",
            "975 Loaded cv987_7394.txt\n",
            "976 Loaded cv983_24219.txt\n",
            "977 Loaded cv986_15092.txt\n",
            "978 Loaded cv985_5964.txt\n",
            "979 Loaded cv999_14636.txt\n",
            "980 Loaded cv991_19973.txt\n",
            "981 Loaded cv975_11920.txt\n",
            "982 Loaded cv973_10171.txt\n",
            "983 Loaded cv972_26837.txt\n",
            "984 Loaded cv974_24303.txt\n",
            "985 Loaded cv977_4776.txt\n",
            "986 Loaded cv971_11790.txt\n",
            "987 Loaded cv976_10724.txt\n",
            "988 Loaded cv980_11851.txt\n",
            "989 Loaded cv979_2029.txt\n",
            "990 Loaded cv978_22192.txt\n",
            "991 Loaded cv969_14760.txt\n",
            "992 Loaded cv961_5578.txt\n",
            "993 Loaded cv965_26688.txt\n",
            "994 Loaded cv962_9813.txt\n",
            "995 Loaded cv963_7208.txt\n",
            "996 Loaded cv968_25413.txt\n",
            "997 Loaded cv964_5794.txt\n",
            "998 Loaded cv967_5626.txt\n",
            "999 Loaded cv966_28671.txt\n",
            "1000 Loaded cv970_19532.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOJIvntYIaq2",
        "outputId": "c0394e9f-7c3d-4e7a-dc1e-cedf543e73f8"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Below is an updated version of cleaning this review for one file cv000_29416.txt\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "import re\n",
        "\n",
        "# # load doc into memory\n",
        "# def load_doc(filename):\n",
        "    # # open the file as read only\n",
        "    # file = open(filename, 'r')\n",
        "    # # read all text\n",
        "    # text = file.read()\n",
        "    # # close the file\n",
        "    # file.close()\n",
        "    # return text\n",
        "\n",
        "directory = '/content/gdrive/My Drive/txt_sentoken/neg'\n",
        "filename = 'cv000_29416.txt'\n",
        "path = directory + '/' + filename\n",
        "\n",
        "# load the document\n",
        "text = load_doc(path)\n",
        "\n",
        "# split into tokens by white space\n",
        "tokens = text.split()\n",
        "\n",
        "# prepare regex for char filtering\n",
        "re_punc = re.compile('[%s]' % re.escape(string.punctuation))\n",
        "\n",
        "# remove punctuation from each word\n",
        "tokens = [re_punc.sub('', w) for w in tokens]\n",
        "\n",
        "# remove remaining tokens that are not alphabetic\n",
        "tokens = [word for word in tokens if word.isalpha()]\n",
        "\n",
        "# filter out stop words\n",
        "stop_words = set(stopwords.words('english'))\n",
        "tokens = [w for w in tokens if not w in stop_words]\n",
        "\n",
        "# filter out short tokens\n",
        "tokens = [word for word in tokens if len(word) > 1]\n",
        "print(tokens)\n",
        "print('\\nNumber of Tokens:',len(tokens))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijkGco4uFMX2",
        "outputId": "ca6de400-2c2f-44dc-9901-1f86503d9cdb"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['plot', 'two', 'teen', 'couples', 'go', 'church', 'party', 'drink', 'drive', 'get', 'accident', 'one', 'guys', 'dies', 'girlfriend', 'continues', 'see', 'life', 'nightmares', 'whats', 'deal', 'watch', 'movie', 'sorta', 'find', 'critique', 'mindfuck', 'movie', 'teen', 'generation', 'touches', 'cool', 'idea', 'presents', 'bad', 'package', 'makes', 'review', 'even', 'harder', 'one', 'write', 'since', 'generally', 'applaud', 'films', 'attempt', 'break', 'mold', 'mess', 'head', 'lost', 'highway', 'memento', 'good', 'bad', 'ways', 'making', 'types', 'films', 'folks', 'didnt', 'snag', 'one', 'correctly', 'seem', 'taken', 'pretty', 'neat', 'concept', 'executed', 'terribly', 'problems', 'movie', 'well', 'main', 'problem', 'simply', 'jumbled', 'starts', 'normal', 'downshifts', 'fantasy', 'world', 'audience', 'member', 'idea', 'whats', 'going', 'dreams', 'characters', 'coming', 'back', 'dead', 'others', 'look', 'like', 'dead', 'strange', 'apparitions', 'disappearances', 'looooot', 'chase', 'scenes', 'tons', 'weird', 'things', 'happen', 'simply', 'explained', 'personally', 'dont', 'mind', 'trying', 'unravel', 'film', 'every', 'give', 'clue', 'get', 'kind', 'fed', 'films', 'biggest', 'problem', 'obviously', 'got', 'big', 'secret', 'hide', 'seems', 'want', 'hide', 'completely', 'final', 'five', 'minutes', 'make', 'things', 'entertaining', 'thrilling', 'even', 'engaging', 'meantime', 'really', 'sad', 'part', 'arrow', 'dig', 'flicks', 'like', 'actually', 'figured', 'halfway', 'point', 'strangeness', 'start', 'make', 'little', 'bit', 'sense', 'still', 'didnt', 'make', 'film', 'entertaining', 'guess', 'bottom', 'line', 'movies', 'like', 'always', 'make', 'sure', 'audience', 'even', 'given', 'secret', 'password', 'enter', 'world', 'understanding', 'mean', 'showing', 'melissa', 'sagemiller', 'running', 'away', 'visions', 'minutes', 'throughout', 'movie', 'plain', 'lazy', 'okay', 'get', 'people', 'chasing', 'dont', 'know', 'really', 'need', 'see', 'giving', 'us', 'different', 'scenes', 'offering', 'insight', 'strangeness', 'going', 'movie', 'apparently', 'studio', 'took', 'film', 'away', 'director', 'chopped', 'shows', 'mightve', 'pretty', 'decent', 'teen', 'mindfuck', 'movie', 'somewhere', 'guess', 'suits', 'decided', 'turning', 'music', 'video', 'little', 'edge', 'would', 'make', 'sense', 'actors', 'pretty', 'good', 'part', 'although', 'wes', 'bentley', 'seemed', 'playing', 'exact', 'character', 'american', 'beauty', 'new', 'neighborhood', 'biggest', 'kudos', 'go', 'sagemiller', 'holds', 'throughout', 'entire', 'film', 'actually', 'feeling', 'characters', 'unraveling', 'overall', 'film', 'doesnt', 'stick', 'doesnt', 'entertain', 'confusing', 'rarely', 'excites', 'feels', 'pretty', 'redundant', 'runtime', 'despite', 'pretty', 'cool', 'ending', 'explanation', 'craziness', 'came', 'oh', 'way', 'horror', 'teen', 'slasher', 'flick', 'packaged', 'look', 'way', 'someone', 'apparently', 'assuming', 'genre', 'still', 'hot', 'kids', 'also', 'wrapped', 'production', 'two', 'years', 'ago', 'sitting', 'shelves', 'ever', 'since', 'whatever', 'skip', 'wheres', 'joblo', 'coming', 'nightmare', 'elm', 'street', 'blair', 'witch', 'crow', 'crow', 'salvation', 'lost', 'highway', 'memento', 'others', 'stir', 'echoes']\n",
            "\n",
            "Number of Tokens: 330\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "29-_0MooFMVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-YdoqDHuFMSu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "jWKwsnRgFMKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "gWKb-2T5B_ac"
      }
    }
  ]
}